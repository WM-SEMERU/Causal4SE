{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal interpretability for Software Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we present a full excercise on the use of SE dataset and the causal effect analysis for software engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction Interpretability for SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Interpretability for SE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case of study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation analysis??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download SEMERU datasets at  https://huggingface.co/semeru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/code/wam/causal4SE/.env_causal/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_control = \"semeru/Code-code-galeras-prompting-3k-control\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"semeru/Code-code-galeras-prompting-3k-treatment-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"semeru/Code-code-galeras-prompting-3k-treatment-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments = \"semeru/galeras-causal4se-3k-levenshtein\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset, cache_dir=\"../../datax\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset['train'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stablish confunder variables as $w\\in W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_token_counts</th>\n",
       "      <th>file_name</th>\n",
       "      <th>d_id</th>\n",
       "      <th>control</th>\n",
       "      <th>w_n_ast_errors</th>\n",
       "      <th>documentation</th>\n",
       "      <th>w_n_whitespaces</th>\n",
       "      <th>w_complexity</th>\n",
       "      <th>path</th>\n",
       "      <th>w_ast_levels</th>\n",
       "      <th>...</th>\n",
       "      <th>w_n_ast_nodes</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>w_n_identifiers</th>\n",
       "      <th>url</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "      <th>fun_name</th>\n",
       "      <th>w_n_words</th>\n",
       "      <th>code</th>\n",
       "      <th>repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>groupby.py</td>\n",
       "      <td>40113</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 77, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        Return a rolling group...</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>pandas/core/groupby/groupby.py</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>TYP: more return annotations in core/ (#47618)...</td>\n",
       "      <td>13</td>\n",
       "      <td>https://github.com/pandas-dev/pandas.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 45, 'n_words':...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 82, 'n_words':...</td>\n",
       "      <td>rolling</td>\n",
       "      <td>18</td>\n",
       "      <td>def rolling(self, *args, **kwargs) -&gt; RollingG...</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>degree_seq.py</td>\n",
       "      <td>42064</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 526, 'n_words'...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Returns a random graph with giv...</td>\n",
       "      <td>417</td>\n",
       "      <td>13</td>\n",
       "      <td>networkx/generators/degree_seq.py</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>375</td>\n",
       "      <td>Remove redundant py2 numeric conversions (#566...</td>\n",
       "      <td>35</td>\n",
       "      <td>https://github.com/networkx/networkx.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 328, 'n_words'...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 555, 'n_words'...</td>\n",
       "      <td>expected_degree_graph</td>\n",
       "      <td>179</td>\n",
       "      <td>def expected_degree_graph(w, seed=None, selflo...</td>\n",
       "      <td>networkx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>base.py</td>\n",
       "      <td>2897</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 0, 'n_words': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Write the evaluation results to...</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>mlflow/models/evaluation/base.py</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>Improve evaluation api (#5256)\\n\\n* init\\r\\n\\r...</td>\n",
       "      <td>22</td>\n",
       "      <td>https://github.com/mlflow/mlflow.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 40, 'n_words':...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 88, 'n_words':...</td>\n",
       "      <td>save</td>\n",
       "      <td>49</td>\n",
       "      <td>def save(self, path):\\n        \\n        os.ma...</td>\n",
       "      <td>mlflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>test_message_builder.py</td>\n",
       "      <td>18592</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 0, 'n_words': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Test that a generic issue type'...</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>tests/sentry/integrations/slack/test_message_b...</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>249</td>\n",
       "      <td>feat(integrations): Support generic issue type...</td>\n",
       "      <td>25</td>\n",
       "      <td>https://github.com/getsentry/sentry.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 120, 'n_words'...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 0, 'n_words': ...</td>\n",
       "      <td>test_build_group_generic_issue_attachment</td>\n",
       "      <td>51</td>\n",
       "      <td>def test_build_group_generic_issue_attachment(...</td>\n",
       "      <td>sentry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>ImageProcessor.py</td>\n",
       "      <td>42906</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 76, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        apply your own functio...</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>xlib/image/ImageProcessor.py</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>ImageProcessor.py refactoring</td>\n",
       "      <td>14</td>\n",
       "      <td>https://github.com/iperov/DeepFaceLive.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 62, 'n_words':...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 248, 'n_words'...</td>\n",
       "      <td>apply</td>\n",
       "      <td>45</td>\n",
       "      <td>def apply(self, func, mask=None) -&gt; 'ImageProc...</td>\n",
       "      <td>DeepFaceLive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>33</td>\n",
       "      <td>sales_order_analysis.py</td>\n",
       "      <td>14521</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 11, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>erpnext/selling/report/sales_order_analysis/sa...</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>style: format code with black</td>\n",
       "      <td>9</td>\n",
       "      <td>https://github.com/frappe/erpnext.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 527, 'n_words'...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 132, 'n_words'...</td>\n",
       "      <td>get_data</td>\n",
       "      <td>14</td>\n",
       "      <td>def get_data(conditions, filters):\\n\\tdata = f...</td>\n",
       "      <td>erpnext</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>31</td>\n",
       "      <td>inspect.py</td>\n",
       "      <td>55277</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 39, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "    Get the mapping of corouti...</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>python3.10.4/Lib/inspect.py</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>add python 3.10.4 for windows</td>\n",
       "      <td>16</td>\n",
       "      <td>https://github.com/XX-net/XX-Net.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 73, 'n_words':...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 87, 'n_words':...</td>\n",
       "      <td>getcoroutinelocals</td>\n",
       "      <td>40</td>\n",
       "      <td>def getcoroutinelocals(coroutine):\\n    \\n    ...</td>\n",
       "      <td>XX-Net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>39</td>\n",
       "      <td>forwardprop_test.py</td>\n",
       "      <td>80975</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 47, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Computes the full Hessian matri...</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>keras/integration_test/forwardprop_test.py</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>Reformatting the codebase with black.\\n\\nPiper...</td>\n",
       "      <td>9</td>\n",
       "      <td>https://github.com/keras-team/keras.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 143, 'n_words'...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 94, 'n_words':...</td>\n",
       "      <td>_forward_over_back_hessian</td>\n",
       "      <td>14</td>\n",
       "      <td>def _forward_over_back_hessian(f, params, use_...</td>\n",
       "      <td>keras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>204</td>\n",
       "      <td>_stochastic_gradient.py</td>\n",
       "      <td>75837</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 302, 'n_words'...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Probability estimates.\n",
       "\n",
       "       ...</td>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>sklearn/linear_model/_stochastic_gradient.py</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>DEP loss \"log\" in favor of \"log loss\" in SGDCl...</td>\n",
       "      <td>24</td>\n",
       "      <td>https://github.com/scikit-learn/scikit-learn.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 374, 'n_words'...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 401, 'n_words'...</td>\n",
       "      <td>predict_proba</td>\n",
       "      <td>125</td>\n",
       "      <td>def predict_proba(self, X):\\n        \\n       ...</td>\n",
       "      <td>scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>122</td>\n",
       "      <td>utils.py</td>\n",
       "      <td>5027</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 38, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Fetch JSON Web Key Sets from a ...</td>\n",
       "      <td>216</td>\n",
       "      <td>5</td>\n",
       "      <td>saleor/plugins/openid_connect/utils.py</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>Make OIDC plugin public (#9406)\\n\\n* Make OIDC...</td>\n",
       "      <td>25</td>\n",
       "      <td>https://github.com/saleor/saleor.git</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 198, 'n_words'...</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 99, 'n_words':...</td>\n",
       "      <td>fetch_jwks</td>\n",
       "      <td>86</td>\n",
       "      <td>def fetch_jwks(jwks_url) -&gt; Optional[dict]:\\n ...</td>\n",
       "      <td>saleor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2923 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w_token_counts                file_name   d_id  \\\n",
       "0                 48               groupby.py  40113   \n",
       "1                240            degree_seq.py  42064   \n",
       "2                153                  base.py   2897   \n",
       "3                137  test_message_builder.py  18592   \n",
       "4                 82        ImageProcessor.py  42906   \n",
       "...              ...                      ...    ...   \n",
       "2918              33  sales_order_analysis.py  14521   \n",
       "2919              31               inspect.py  55277   \n",
       "2920              39      forwardprop_test.py  80975   \n",
       "2921             204  _stochastic_gradient.py  75837   \n",
       "2922             122                 utils.py   5027   \n",
       "\n",
       "                                                control  w_n_ast_errors  \\\n",
       "0     {'predicted': {'n_whitespaces': 77, 'n_words':...               0   \n",
       "1     {'predicted': {'n_whitespaces': 526, 'n_words'...               0   \n",
       "2     {'predicted': {'n_whitespaces': 0, 'n_words': ...               0   \n",
       "3     {'predicted': {'n_whitespaces': 0, 'n_words': ...               0   \n",
       "4     {'predicted': {'n_whitespaces': 76, 'n_words':...               0   \n",
       "...                                                 ...             ...   \n",
       "2918  {'predicted': {'n_whitespaces': 11, 'n_words':...               0   \n",
       "2919  {'predicted': {'n_whitespaces': 39, 'n_words':...               0   \n",
       "2920  {'predicted': {'n_whitespaces': 47, 'n_words':...               0   \n",
       "2921  {'predicted': {'n_whitespaces': 302, 'n_words'...               0   \n",
       "2922  {'predicted': {'n_whitespaces': 38, 'n_words':...               0   \n",
       "\n",
       "                                          documentation  w_n_whitespaces  \\\n",
       "0     {'docstring': '\n",
       "        Return a rolling group...              101   \n",
       "1     {'docstring': 'Returns a random graph with giv...              417   \n",
       "2     {'docstring': 'Write the evaluation results to...              208   \n",
       "3     {'docstring': 'Test that a generic issue type'...              154   \n",
       "4     {'docstring': '\n",
       "        apply your own functio...              127   \n",
       "...                                                 ...              ...   \n",
       "2918  {'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...                5   \n",
       "2919  {'docstring': '\n",
       "    Get the mapping of corouti...              140   \n",
       "2920  {'docstring': 'Computes the full Hessian matri...               51   \n",
       "2921  {'docstring': 'Probability estimates.\n",
       "\n",
       "       ...              603   \n",
       "2922  {'docstring': 'Fetch JSON Web Key Sets from a ...              216   \n",
       "\n",
       "      w_complexity                                               path  \\\n",
       "0                1                     pandas/core/groupby/groupby.py   \n",
       "1               13                  networkx/generators/degree_seq.py   \n",
       "2                3                   mlflow/models/evaluation/base.py   \n",
       "3                1  tests/sentry/integrations/slack/test_message_b...   \n",
       "4                3                       xlib/image/ImageProcessor.py   \n",
       "...            ...                                                ...   \n",
       "2918             1  erpnext/selling/report/sales_order_analysis/sa...   \n",
       "2919             2                        python3.10.4/Lib/inspect.py   \n",
       "2920             1         keras/integration_test/forwardprop_test.py   \n",
       "2921             6       sklearn/linear_model/_stochastic_gradient.py   \n",
       "2922             5             saleor/plugins/openid_connect/utils.py   \n",
       "\n",
       "      w_ast_levels  ...  w_n_ast_nodes  \\\n",
       "0                9  ...             71   \n",
       "1               17  ...            375   \n",
       "2               13  ...            253   \n",
       "3               12  ...            249   \n",
       "4               13  ...            137   \n",
       "...            ...  ...            ...   \n",
       "2918            11  ...             51   \n",
       "2919             9  ...            118   \n",
       "2920             9  ...             55   \n",
       "2921            17  ...            328   \n",
       "2922            12  ...            210   \n",
       "\n",
       "                                         commit_message  w_n_identifiers  \\\n",
       "0     TYP: more return annotations in core/ (#47618)...               13   \n",
       "1     Remove redundant py2 numeric conversions (#566...               35   \n",
       "2     Improve evaluation api (#5256)\\n\\n* init\\r\\n\\r...               22   \n",
       "3     feat(integrations): Support generic issue type...               25   \n",
       "4                         ImageProcessor.py refactoring               14   \n",
       "...                                                 ...              ...   \n",
       "2918                      style: format code with black                9   \n",
       "2919                      add python 3.10.4 for windows               16   \n",
       "2920  Reformatting the codebase with black.\\n\\nPiper...                9   \n",
       "2921  DEP loss \"log\" in favor of \"log loss\" in SGDCl...               24   \n",
       "2922  Make OIDC plugin public (#9406)\\n\\n* Make OIDC...               25   \n",
       "\n",
       "                                                   url  \\\n",
       "0             https://github.com/pandas-dev/pandas.git   \n",
       "1             https://github.com/networkx/networkx.git   \n",
       "2                 https://github.com/mlflow/mlflow.git   \n",
       "3              https://github.com/getsentry/sentry.git   \n",
       "4           https://github.com/iperov/DeepFaceLive.git   \n",
       "...                                                ...   \n",
       "2918             https://github.com/frappe/erpnext.git   \n",
       "2919              https://github.com/XX-net/XX-Net.git   \n",
       "2920           https://github.com/keras-team/keras.git   \n",
       "2921  https://github.com/scikit-learn/scikit-learn.git   \n",
       "2922              https://github.com/saleor/saleor.git   \n",
       "\n",
       "                                                     T2  \\\n",
       "0     {'predicted': {'n_whitespaces': 45, 'n_words':...   \n",
       "1     {'predicted': {'n_whitespaces': 328, 'n_words'...   \n",
       "2     {'predicted': {'n_whitespaces': 40, 'n_words':...   \n",
       "3     {'predicted': {'n_whitespaces': 120, 'n_words'...   \n",
       "4     {'predicted': {'n_whitespaces': 62, 'n_words':...   \n",
       "...                                                 ...   \n",
       "2918  {'predicted': {'n_whitespaces': 527, 'n_words'...   \n",
       "2919  {'predicted': {'n_whitespaces': 73, 'n_words':...   \n",
       "2920  {'predicted': {'n_whitespaces': 143, 'n_words'...   \n",
       "2921  {'predicted': {'n_whitespaces': 374, 'n_words'...   \n",
       "2922  {'predicted': {'n_whitespaces': 198, 'n_words'...   \n",
       "\n",
       "                                                     T1  \\\n",
       "0     {'predicted': {'n_whitespaces': 82, 'n_words':...   \n",
       "1     {'predicted': {'n_whitespaces': 555, 'n_words'...   \n",
       "2     {'predicted': {'n_whitespaces': 88, 'n_words':...   \n",
       "3     {'predicted': {'n_whitespaces': 0, 'n_words': ...   \n",
       "4     {'predicted': {'n_whitespaces': 248, 'n_words'...   \n",
       "...                                                 ...   \n",
       "2918  {'predicted': {'n_whitespaces': 132, 'n_words'...   \n",
       "2919  {'predicted': {'n_whitespaces': 87, 'n_words':...   \n",
       "2920  {'predicted': {'n_whitespaces': 94, 'n_words':...   \n",
       "2921  {'predicted': {'n_whitespaces': 401, 'n_words'...   \n",
       "2922  {'predicted': {'n_whitespaces': 99, 'n_words':...   \n",
       "\n",
       "                                       fun_name  w_n_words  \\\n",
       "0                                       rolling         18   \n",
       "1                         expected_degree_graph        179   \n",
       "2                                          save         49   \n",
       "3     test_build_group_generic_issue_attachment         51   \n",
       "4                                         apply         45   \n",
       "...                                         ...        ...   \n",
       "2918                                   get_data         14   \n",
       "2919                         getcoroutinelocals         40   \n",
       "2920                 _forward_over_back_hessian         14   \n",
       "2921                              predict_proba        125   \n",
       "2922                                 fetch_jwks         86   \n",
       "\n",
       "                                                   code          repo  \n",
       "0     def rolling(self, *args, **kwargs) -> RollingG...        pandas  \n",
       "1     def expected_degree_graph(w, seed=None, selflo...      networkx  \n",
       "2     def save(self, path):\\n        \\n        os.ma...        mlflow  \n",
       "3     def test_build_group_generic_issue_attachment(...        sentry  \n",
       "4     def apply(self, func, mask=None) -> 'ImageProc...  DeepFaceLive  \n",
       "...                                                 ...           ...  \n",
       "2918  def get_data(conditions, filters):\\n\\tdata = f...       erpnext  \n",
       "2919  def getcoroutinelocals(coroutine):\\n    \\n    ...        XX-Net  \n",
       "2920  def _forward_over_back_hessian(f, params, use_...         keras  \n",
       "2921  def predict_proba(self, X):\\n        \\n       ...  scikit-learn  \n",
       "2922  def fetch_jwks(jwks_url) -> Optional[dict]:\\n ...        saleor  \n",
       "\n",
       "[2923 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns={'vocab_size':'w_vocab_size','n_words':'w_n_words','n_ast_errors':'w_n_ast_errors','ast_levels':'w_ast_levels','n_whitespaces':'w_n_whitespaces','complexity':'w_complexity','nloc':'w_nloc','token_counts':'w_token_counts','n_ast_nodes':'w_n_ast_nodes','ast_errors':'w_ast_errors','n_identifiers':'w_n_identifiers'}\n",
    "df = df.rename(columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have nested data for some columns we will flatten all this information, i.e. flattening the documentation column and its related metrics such as the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>docstring</th>\n",
       "      <th>language</th>\n",
       "      <th>n_whitespaces</th>\n",
       "      <th>n_words</th>\n",
       "      <th>vocab_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167770</td>\n",
       "      <td>def rolling(self, *args, **kwargs) -&gt; RollingG...</td>\n",
       "      <td>\\n        Return a rolling grouper, providing ...</td>\n",
       "      <td>en</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176730</td>\n",
       "      <td>def expected_degree_graph(w, seed=None, selflo...</td>\n",
       "      <td>Returns a random graph with given expected deg...</td>\n",
       "      <td>en</td>\n",
       "      <td>524</td>\n",
       "      <td>298</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19151</td>\n",
       "      <td>def save(self, path):\\n        \\n        os.ma...</td>\n",
       "      <td>Write the evaluation results to the specified ...</td>\n",
       "      <td>en</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89933</td>\n",
       "      <td>def test_build_group_generic_issue_attachment(...</td>\n",
       "      <td>Test that a generic issue type's Slack alert c...</td>\n",
       "      <td>en</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179114</td>\n",
       "      <td>def apply(self, func, mask=None) -&gt; 'ImageProc...</td>\n",
       "      <td>\\n        apply your own function on internal ...</td>\n",
       "      <td>en</td>\n",
       "      <td>79</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>67430</td>\n",
       "      <td>def get_data(conditions, filters):\\n\\tdata = f...</td>\n",
       "      <td>\\n\\t\\tSELECT\\n\\t\\t\\tso.transaction_date as dat...</td>\n",
       "      <td>en</td>\n",
       "      <td>112</td>\n",
       "      <td>146</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>218391</td>\n",
       "      <td>def getcoroutinelocals(coroutine):\\n    \\n    ...</td>\n",
       "      <td>\\n    Get the mapping of coroutine local varia...</td>\n",
       "      <td>en</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>272189</td>\n",
       "      <td>def _forward_over_back_hessian(f, params, use_...</td>\n",
       "      <td>Computes the full Hessian matrix for the scala...</td>\n",
       "      <td>en</td>\n",
       "      <td>166</td>\n",
       "      <td>105</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>259605</td>\n",
       "      <td>def predict_proba(self, X):\\n        \\n       ...</td>\n",
       "      <td>Probability estimates.\\n\\n        This method ...</td>\n",
       "      <td>en</td>\n",
       "      <td>339</td>\n",
       "      <td>138</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>26573</td>\n",
       "      <td>def fetch_jwks(jwks_url) -&gt; Optional[dict]:\\n ...</td>\n",
       "      <td>Fetch JSON Web Key Sets from a provider.\\n\\n  ...</td>\n",
       "      <td>en</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2923 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               code  \\\n",
       "0     167770  def rolling(self, *args, **kwargs) -> RollingG...   \n",
       "1     176730  def expected_degree_graph(w, seed=None, selflo...   \n",
       "2      19151  def save(self, path):\\n        \\n        os.ma...   \n",
       "3      89933  def test_build_group_generic_issue_attachment(...   \n",
       "4     179114  def apply(self, func, mask=None) -> 'ImageProc...   \n",
       "...      ...                                                ...   \n",
       "2918   67430  def get_data(conditions, filters):\\n\\tdata = f...   \n",
       "2919  218391  def getcoroutinelocals(coroutine):\\n    \\n    ...   \n",
       "2920  272189  def _forward_over_back_hessian(f, params, use_...   \n",
       "2921  259605  def predict_proba(self, X):\\n        \\n       ...   \n",
       "2922   26573  def fetch_jwks(jwks_url) -> Optional[dict]:\\n ...   \n",
       "\n",
       "                                              docstring language  \\\n",
       "0     \\n        Return a rolling grouper, providing ...       en   \n",
       "1     Returns a random graph with given expected deg...       en   \n",
       "2     Write the evaluation results to the specified ...       en   \n",
       "3     Test that a generic issue type's Slack alert c...       en   \n",
       "4     \\n        apply your own function on internal ...       en   \n",
       "...                                                 ...      ...   \n",
       "2918  \\n\\t\\tSELECT\\n\\t\\t\\tso.transaction_date as dat...       en   \n",
       "2919  \\n    Get the mapping of coroutine local varia...       en   \n",
       "2920  Computes the full Hessian matrix for the scala...       en   \n",
       "2921  Probability estimates.\\n\\n        This method ...       en   \n",
       "2922  Fetch JSON Web Key Sets from a provider.\\n\\n  ...       en   \n",
       "\n",
       "      n_whitespaces  n_words  vocab_size  \n",
       "0                24        9           8  \n",
       "1               524      298         173  \n",
       "2                 9       10           9  \n",
       "3                11       12          12  \n",
       "4                79       31          30  \n",
       "...             ...      ...         ...  \n",
       "2918            112      146         102  \n",
       "2919             36       27          22  \n",
       "2920            166      105          73  \n",
       "2921            339      138          98  \n",
       "2922             37       25          24  \n",
       "\n",
       "[2923 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentation_df = pd.concat([df['id'], df['code'], df['documentation'].apply(pd.Series)], axis=1)\n",
    "documentation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_treatment(df,t_name,binary_treatment):\n",
    "    prefix = \"e\"\n",
    "    result = pd.concat([df, df[t_name].apply(pd.Series)], axis=1)\n",
    "    result = pd.concat([result.drop(['predicted'], axis=1), result['predicted'].apply(pd.Series)], axis=1)\n",
    "    new_column_names = {'n_whitespaces':prefix+'_n_whitespaces', 'n_words':prefix+'_n_words', 'vocab_size':prefix+'_vocab_size'}\n",
    "    result.rename(columns=new_column_names, inplace=True)\n",
    "    \n",
    "    \n",
    "    prefix = \"i\"\n",
    "    result = pd.concat([result.drop(['prompt'],axis=1),result['prompt'].apply(pd.Series)], axis=1)\n",
    "    new_column_names = {'n_whitespaces':prefix+'_n_whitespaces', 'p_n_words':prefix+'_n_words', 'vocab_size':prefix+'_vocab_size'}\n",
    "    result.rename(columns=new_column_names, inplace=True)\n",
    "    result['i_binary_treatment'] = binary_treatment\n",
    "    result['i_treatment'] = t_name\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create each treatment dataset $t\\in T$.\n",
    "\n",
    "- Control template: \"Complete the following python method: ```{Random_cut code}```\",\n",
    "- Treatment 1 (T1): \"Write a Python method that starts with ```{Function Name}``` , I need to complete this function. Remove comments, summary and descriptions.\",\n",
    "- Treatment 2 (T2): \"Remeber you have a Python function named ```{Method Signature}```, the function starts with the following code ```{Random_cut code}```. The description for the function is: ```{docstring}``` remove comments; remove summary; remove description; Return only the code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = flatten_treatment(df, \"control\", False)\n",
    "T1= flatten_treatment(df, \"T1\", True)\n",
    "T2 = flatten_treatment(df, \"T2\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w_token_counts',\n",
       " 'file_name',\n",
       " 'd_id',\n",
       " 'control',\n",
       " 'w_n_ast_errors',\n",
       " 'documentation',\n",
       " 'w_n_whitespaces',\n",
       " 'w_complexity',\n",
       " 'path',\n",
       " 'w_ast_levels',\n",
       " 'w_vocab_size',\n",
       " 'language',\n",
       " 'id',\n",
       " 'random_cut',\n",
       " 'w_ast_errors',\n",
       " 'commit_id',\n",
       " 'w_nloc',\n",
       " 'w_n_ast_nodes',\n",
       " 'commit_message',\n",
       " 'w_n_identifiers',\n",
       " 'url',\n",
       " 'T2',\n",
       " 'T1',\n",
       " 'fun_name',\n",
       " 'w_n_words',\n",
       " 'code',\n",
       " 'repo',\n",
       " 'e_n_whitespaces',\n",
       " 'e_n_words',\n",
       " 'prediction',\n",
       " 'e_vocab_size',\n",
       " 'i_n_whitespaces',\n",
       " 'i_n_words',\n",
       " 'template',\n",
       " 'i_vocab_size',\n",
       " 'i_binary_treatment',\n",
       " 'i_treatment']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_token_counts</th>\n",
       "      <th>file_name</th>\n",
       "      <th>d_id</th>\n",
       "      <th>control</th>\n",
       "      <th>w_n_ast_errors</th>\n",
       "      <th>documentation</th>\n",
       "      <th>w_n_whitespaces</th>\n",
       "      <th>w_complexity</th>\n",
       "      <th>path</th>\n",
       "      <th>w_ast_levels</th>\n",
       "      <th>...</th>\n",
       "      <th>e_n_whitespaces</th>\n",
       "      <th>e_n_words</th>\n",
       "      <th>prediction</th>\n",
       "      <th>e_vocab_size</th>\n",
       "      <th>i_n_whitespaces</th>\n",
       "      <th>i_n_words</th>\n",
       "      <th>template</th>\n",
       "      <th>i_vocab_size</th>\n",
       "      <th>i_binary_treatment</th>\n",
       "      <th>i_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>groupby.py</td>\n",
       "      <td>40113</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 77, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        Return a rolling group...</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>pandas/core/groupby/groupby.py</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>Certainly! Here's the completed code:\\n\\n```py...</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>degree_seq.py</td>\n",
       "      <td>42064</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 526, 'n_words'...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Returns a random graph with giv...</td>\n",
       "      <td>417</td>\n",
       "      <td>13</td>\n",
       "      <td>networkx/generators/degree_seq.py</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>526</td>\n",
       "      <td>332</td>\n",
       "      <td>Here is the completed python method:\\n\\n```pyt...</td>\n",
       "      <td>182</td>\n",
       "      <td>380</td>\n",
       "      <td>175</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>base.py</td>\n",
       "      <td>2897</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 0, 'n_words': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Write the evaluation results to...</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>mlflow/models/evaluation/base.py</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>exist_ok=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>test_message_builder.py</td>\n",
       "      <td>18592</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 0, 'n_words': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Test that a generic issue type'...</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>tests/sentry/integrations/slack/test_message_b...</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"danger\"</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>50</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>ImageProcessor.py</td>\n",
       "      <td>42906</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 76, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        apply your own functio...</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>xlib/image/ImageProcessor.py</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "      <td>```\\n        mask = mask.astype(bool)\\n       ...</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>38</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>33</td>\n",
       "      <td>sales_order_analysis.py</td>\n",
       "      <td>14521</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 11, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>erpnext/selling/report/sales_order_analysis/sa...</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>def get_data(conditions, filters):\\n\\tdata = f...</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>31</td>\n",
       "      <td>inspect.py</td>\n",
       "      <td>55277</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 39, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "    Get the mapping of corouti...</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>python3.10.4/Lib/inspect.py</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>```python\\ndef getcoroutinelocals(coroutine):\\...</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>39</td>\n",
       "      <td>forwardprop_test.py</td>\n",
       "      <td>80975</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 47, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Computes the full Hessian matri...</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>keras/integration_test/forwardprop_test.py</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>def _forward_over_back_hessian(f, params, use_...</td>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>204</td>\n",
       "      <td>_stochastic_gradient.py</td>\n",
       "      <td>75837</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 302, 'n_words'...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Probability estimates.\n",
       "\n",
       "       ...</td>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>sklearn/linear_model/_stochastic_gradient.py</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>302</td>\n",
       "      <td>80</td>\n",
       "      <td>def predict_proba(self, X):\\n        \\n    che...</td>\n",
       "      <td>49</td>\n",
       "      <td>488</td>\n",
       "      <td>110</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>122</td>\n",
       "      <td>utils.py</td>\n",
       "      <td>5027</td>\n",
       "      <td>{'predicted': {'n_whitespaces': 38, 'n_words':...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Fetch JSON Web Key Sets from a ...</td>\n",
       "      <td>216</td>\n",
       "      <td>5</td>\n",
       "      <td>saleor/plugins/openid_connect/utils.py</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>if keys:\\n        return keys\\n    else:\\n    ...</td>\n",
       "      <td>13</td>\n",
       "      <td>195</td>\n",
       "      <td>78</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2923 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w_token_counts                file_name   d_id  \\\n",
       "0                 48               groupby.py  40113   \n",
       "1                240            degree_seq.py  42064   \n",
       "2                153                  base.py   2897   \n",
       "3                137  test_message_builder.py  18592   \n",
       "4                 82        ImageProcessor.py  42906   \n",
       "...              ...                      ...    ...   \n",
       "2918              33  sales_order_analysis.py  14521   \n",
       "2919              31               inspect.py  55277   \n",
       "2920              39      forwardprop_test.py  80975   \n",
       "2921             204  _stochastic_gradient.py  75837   \n",
       "2922             122                 utils.py   5027   \n",
       "\n",
       "                                                control  w_n_ast_errors  \\\n",
       "0     {'predicted': {'n_whitespaces': 77, 'n_words':...               0   \n",
       "1     {'predicted': {'n_whitespaces': 526, 'n_words'...               0   \n",
       "2     {'predicted': {'n_whitespaces': 0, 'n_words': ...               0   \n",
       "3     {'predicted': {'n_whitespaces': 0, 'n_words': ...               0   \n",
       "4     {'predicted': {'n_whitespaces': 76, 'n_words':...               0   \n",
       "...                                                 ...             ...   \n",
       "2918  {'predicted': {'n_whitespaces': 11, 'n_words':...               0   \n",
       "2919  {'predicted': {'n_whitespaces': 39, 'n_words':...               0   \n",
       "2920  {'predicted': {'n_whitespaces': 47, 'n_words':...               0   \n",
       "2921  {'predicted': {'n_whitespaces': 302, 'n_words'...               0   \n",
       "2922  {'predicted': {'n_whitespaces': 38, 'n_words':...               0   \n",
       "\n",
       "                                          documentation  w_n_whitespaces  \\\n",
       "0     {'docstring': '\n",
       "        Return a rolling group...              101   \n",
       "1     {'docstring': 'Returns a random graph with giv...              417   \n",
       "2     {'docstring': 'Write the evaluation results to...              208   \n",
       "3     {'docstring': 'Test that a generic issue type'...              154   \n",
       "4     {'docstring': '\n",
       "        apply your own functio...              127   \n",
       "...                                                 ...              ...   \n",
       "2918  {'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...                5   \n",
       "2919  {'docstring': '\n",
       "    Get the mapping of corouti...              140   \n",
       "2920  {'docstring': 'Computes the full Hessian matri...               51   \n",
       "2921  {'docstring': 'Probability estimates.\n",
       "\n",
       "       ...              603   \n",
       "2922  {'docstring': 'Fetch JSON Web Key Sets from a ...              216   \n",
       "\n",
       "      w_complexity                                               path  \\\n",
       "0                1                     pandas/core/groupby/groupby.py   \n",
       "1               13                  networkx/generators/degree_seq.py   \n",
       "2                3                   mlflow/models/evaluation/base.py   \n",
       "3                1  tests/sentry/integrations/slack/test_message_b...   \n",
       "4                3                       xlib/image/ImageProcessor.py   \n",
       "...            ...                                                ...   \n",
       "2918             1  erpnext/selling/report/sales_order_analysis/sa...   \n",
       "2919             2                        python3.10.4/Lib/inspect.py   \n",
       "2920             1         keras/integration_test/forwardprop_test.py   \n",
       "2921             6       sklearn/linear_model/_stochastic_gradient.py   \n",
       "2922             5             saleor/plugins/openid_connect/utils.py   \n",
       "\n",
       "      w_ast_levels  ...  e_n_whitespaces e_n_words  \\\n",
       "0                9  ...               77        72   \n",
       "1               17  ...              526       332   \n",
       "2               13  ...                0         1   \n",
       "3               12  ...                0         1   \n",
       "4               13  ...               76        32   \n",
       "...            ...  ...              ...       ...   \n",
       "2918            11  ...               11        18   \n",
       "2919             9  ...               39        19   \n",
       "2920             9  ...               47        14   \n",
       "2921            17  ...              302        80   \n",
       "2922            12  ...               38        15   \n",
       "\n",
       "                                             prediction e_vocab_size  \\\n",
       "0     Certainly! Here's the completed code:\\n\\n```py...           53   \n",
       "1     Here is the completed python method:\\n\\n```pyt...          182   \n",
       "2                                        exist_ok=True)            1   \n",
       "3                                              \"danger\"            1   \n",
       "4     ```\\n        mask = mask.astype(bool)\\n       ...           28   \n",
       "...                                                 ...          ...   \n",
       "2918  def get_data(conditions, filters):\\n\\tdata = f...           17   \n",
       "2919  ```python\\ndef getcoroutinelocals(coroutine):\\...           17   \n",
       "2920  def _forward_over_back_hessian(f, params, use_...           13   \n",
       "2921  def predict_proba(self, X):\\n        \\n    che...           49   \n",
       "2922  if keys:\\n        return keys\\n    else:\\n    ...           13   \n",
       "\n",
       "     i_n_whitespaces i_n_words  \\\n",
       "0                 29        16   \n",
       "1                380       175   \n",
       "2                 23         9   \n",
       "3                152        50   \n",
       "4                 86        38   \n",
       "...              ...       ...   \n",
       "2918               9        16   \n",
       "2919              53        30   \n",
       "2920              54        19   \n",
       "2921             488       110   \n",
       "2922             195        78   \n",
       "\n",
       "                                            template  i_vocab_size  \\\n",
       "0     Complete the following python method: ```{}```            16   \n",
       "1     Complete the following python method: ```{}```           100   \n",
       "2     Complete the following python method: ```{}```             9   \n",
       "3     Complete the following python method: ```{}```            38   \n",
       "4     Complete the following python method: ```{}```            34   \n",
       "...                                              ...           ...   \n",
       "2918  Complete the following python method: ```{}```            16   \n",
       "2919  Complete the following python method: ```{}```            28   \n",
       "2920  Complete the following python method: ```{}```            18   \n",
       "2921  Complete the following python method: ```{}```            74   \n",
       "2922  Complete the following python method: ```{}```            53   \n",
       "\n",
       "     i_binary_treatment  i_treatment  \n",
       "0                 False      control  \n",
       "1                 False      control  \n",
       "2                 False      control  \n",
       "3                 False      control  \n",
       "4                 False      control  \n",
       "...                 ...          ...  \n",
       "2918              False      control  \n",
       "2919              False      control  \n",
       "2920              False      control  \n",
       "2921              False      control  \n",
       "2922              False      control  \n",
       "\n",
       "[2923 rows x 37 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_df = pd.concat([control_df, T1, T2], join=\"inner\", ignore_index=True)\n",
    "treatments_df = treatments_df.drop(columns=['control', 'T1', 'T2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_token_counts</th>\n",
       "      <th>file_name</th>\n",
       "      <th>d_id</th>\n",
       "      <th>w_n_ast_errors</th>\n",
       "      <th>documentation</th>\n",
       "      <th>w_n_whitespaces</th>\n",
       "      <th>w_complexity</th>\n",
       "      <th>path</th>\n",
       "      <th>w_ast_levels</th>\n",
       "      <th>w_vocab_size</th>\n",
       "      <th>...</th>\n",
       "      <th>e_n_whitespaces</th>\n",
       "      <th>e_n_words</th>\n",
       "      <th>prediction</th>\n",
       "      <th>e_vocab_size</th>\n",
       "      <th>i_n_whitespaces</th>\n",
       "      <th>i_n_words</th>\n",
       "      <th>template</th>\n",
       "      <th>i_vocab_size</th>\n",
       "      <th>i_binary_treatment</th>\n",
       "      <th>i_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>groupby.py</td>\n",
       "      <td>40113</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        Return a rolling group...</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>pandas/core/groupby/groupby.py</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>Certainly! Here's the completed code:\\n\\n```py...</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>degree_seq.py</td>\n",
       "      <td>42064</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Returns a random graph with giv...</td>\n",
       "      <td>417</td>\n",
       "      <td>13</td>\n",
       "      <td>networkx/generators/degree_seq.py</td>\n",
       "      <td>17</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>526</td>\n",
       "      <td>332</td>\n",
       "      <td>Here is the completed python method:\\n\\n```pyt...</td>\n",
       "      <td>182</td>\n",
       "      <td>380</td>\n",
       "      <td>175</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>base.py</td>\n",
       "      <td>2897</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Write the evaluation results to...</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>mlflow/models/evaluation/base.py</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>exist_ok=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>test_message_builder.py</td>\n",
       "      <td>18592</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Test that a generic issue type'...</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>tests/sentry/integrations/slack/test_message_b...</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"danger\"</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>50</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>ImageProcessor.py</td>\n",
       "      <td>42906</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        apply your own functio...</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>xlib/image/ImageProcessor.py</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "      <td>```\\n        mask = mask.astype(bool)\\n       ...</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>38</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>33</td>\n",
       "      <td>sales_order_analysis.py</td>\n",
       "      <td>14521</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>erpnext/selling/report/sales_order_analysis/sa...</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>527</td>\n",
       "      <td>170</td>\n",
       "      <td>Sure! Here's the code without the comments, su...</td>\n",
       "      <td>122</td>\n",
       "      <td>148</td>\n",
       "      <td>188</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>134</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>31</td>\n",
       "      <td>inspect.py</td>\n",
       "      <td>55277</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "    Get the mapping of corouti...</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>python3.10.4/Lib/inspect.py</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>55</td>\n",
       "      <td>Certainly! Here's the code for the `getcorouti...</td>\n",
       "      <td>41</td>\n",
       "      <td>112</td>\n",
       "      <td>83</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>39</td>\n",
       "      <td>forwardprop_test.py</td>\n",
       "      <td>80975</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Computes the full Hessian matri...</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>keras/integration_test/forwardprop_test.py</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>87</td>\n",
       "      <td>Sure! Here's the code for the `_forward_over_b...</td>\n",
       "      <td>65</td>\n",
       "      <td>243</td>\n",
       "      <td>150</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>204</td>\n",
       "      <td>_stochastic_gradient.py</td>\n",
       "      <td>75837</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Probability estimates.\n",
       "\n",
       "       ...</td>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>sklearn/linear_model/_stochastic_gradient.py</td>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>374</td>\n",
       "      <td>116</td>\n",
       "      <td>Certainly! Here's the code without comments, s...</td>\n",
       "      <td>78</td>\n",
       "      <td>846</td>\n",
       "      <td>274</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>180</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>122</td>\n",
       "      <td>utils.py</td>\n",
       "      <td>5027</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Fetch JSON Web Key Sets from a ...</td>\n",
       "      <td>216</td>\n",
       "      <td>5</td>\n",
       "      <td>saleor/plugins/openid_connect/utils.py</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>88</td>\n",
       "      <td>Sure, here is the `fetch_jwks` function withou...</td>\n",
       "      <td>62</td>\n",
       "      <td>255</td>\n",
       "      <td>129</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8769 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w_token_counts                file_name   d_id  w_n_ast_errors  \\\n",
       "0                 48               groupby.py  40113               0   \n",
       "1                240            degree_seq.py  42064               0   \n",
       "2                153                  base.py   2897               0   \n",
       "3                137  test_message_builder.py  18592               0   \n",
       "4                 82        ImageProcessor.py  42906               0   \n",
       "...              ...                      ...    ...             ...   \n",
       "8764              33  sales_order_analysis.py  14521               0   \n",
       "8765              31               inspect.py  55277               0   \n",
       "8766              39      forwardprop_test.py  80975               0   \n",
       "8767             204  _stochastic_gradient.py  75837               0   \n",
       "8768             122                 utils.py   5027               0   \n",
       "\n",
       "                                          documentation  w_n_whitespaces  \\\n",
       "0     {'docstring': '\n",
       "        Return a rolling group...              101   \n",
       "1     {'docstring': 'Returns a random graph with giv...              417   \n",
       "2     {'docstring': 'Write the evaluation results to...              208   \n",
       "3     {'docstring': 'Test that a generic issue type'...              154   \n",
       "4     {'docstring': '\n",
       "        apply your own functio...              127   \n",
       "...                                                 ...              ...   \n",
       "8764  {'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...                5   \n",
       "8765  {'docstring': '\n",
       "    Get the mapping of corouti...              140   \n",
       "8766  {'docstring': 'Computes the full Hessian matri...               51   \n",
       "8767  {'docstring': 'Probability estimates.\n",
       "\n",
       "       ...              603   \n",
       "8768  {'docstring': 'Fetch JSON Web Key Sets from a ...              216   \n",
       "\n",
       "      w_complexity                                               path  \\\n",
       "0                1                     pandas/core/groupby/groupby.py   \n",
       "1               13                  networkx/generators/degree_seq.py   \n",
       "2                3                   mlflow/models/evaluation/base.py   \n",
       "3                1  tests/sentry/integrations/slack/test_message_b...   \n",
       "4                3                       xlib/image/ImageProcessor.py   \n",
       "...            ...                                                ...   \n",
       "8764             1  erpnext/selling/report/sales_order_analysis/sa...   \n",
       "8765             2                        python3.10.4/Lib/inspect.py   \n",
       "8766             1         keras/integration_test/forwardprop_test.py   \n",
       "8767             6       sklearn/linear_model/_stochastic_gradient.py   \n",
       "8768             5             saleor/plugins/openid_connect/utils.py   \n",
       "\n",
       "      w_ast_levels  w_vocab_size  ... e_n_whitespaces  e_n_words  \\\n",
       "0                9            17  ...              77         72   \n",
       "1               17            97  ...             526        332   \n",
       "2               13            36  ...               0          1   \n",
       "3               12            38  ...               0          1   \n",
       "4               13            34  ...              76         32   \n",
       "...            ...           ...  ...             ...        ...   \n",
       "8764            11            13  ...             527        170   \n",
       "8765             9            33  ...              73         55   \n",
       "8766             9            13  ...             143         87   \n",
       "8767            17            85  ...             374        116   \n",
       "8768            12            59  ...             198         88   \n",
       "\n",
       "                                             prediction e_vocab_size  \\\n",
       "0     Certainly! Here's the completed code:\\n\\n```py...           53   \n",
       "1     Here is the completed python method:\\n\\n```pyt...          182   \n",
       "2                                        exist_ok=True)            1   \n",
       "3                                              \"danger\"            1   \n",
       "4     ```\\n        mask = mask.astype(bool)\\n       ...           28   \n",
       "...                                                 ...          ...   \n",
       "8764  Sure! Here's the code without the comments, su...          122   \n",
       "8765  Certainly! Here's the code for the `getcorouti...           41   \n",
       "8766  Sure! Here's the code for the `_forward_over_b...           65   \n",
       "8767  Certainly! Here's the code without comments, s...           78   \n",
       "8768  Sure, here is the `fetch_jwks` function withou...           62   \n",
       "\n",
       "     i_n_whitespaces  i_n_words  \\\n",
       "0                 29         16   \n",
       "1                380        175   \n",
       "2                 23          9   \n",
       "3                152         50   \n",
       "4                 86         38   \n",
       "...              ...        ...   \n",
       "8764             148        188   \n",
       "8765             112         83   \n",
       "8766             243        150   \n",
       "8767             846        274   \n",
       "8768             255        129   \n",
       "\n",
       "                                               template i_vocab_size  \\\n",
       "0        Complete the following python method: ```{}```           16   \n",
       "1        Complete the following python method: ```{}```          100   \n",
       "2        Complete the following python method: ```{}```            9   \n",
       "3        Complete the following python method: ```{}```           38   \n",
       "4        Complete the following python method: ```{}```           34   \n",
       "...                                                 ...          ...   \n",
       "8764  Remeber you have a Python function named {}, t...          134   \n",
       "8765  Remeber you have a Python function named {}, t...           65   \n",
       "8766  Remeber you have a Python function named {}, t...          104   \n",
       "8767  Remeber you have a Python function named {}, t...          180   \n",
       "8768  Remeber you have a Python function named {}, t...           89   \n",
       "\n",
       "      i_binary_treatment i_treatment  \n",
       "0                  False     control  \n",
       "1                  False     control  \n",
       "2                  False     control  \n",
       "3                  False     control  \n",
       "4                  False     control  \n",
       "...                  ...         ...  \n",
       "8764                True          T2  \n",
       "8765                True          T2  \n",
       "8766                True          T2  \n",
       "8767                True          T2  \n",
       "8768                True          T2  \n",
       "\n",
       "[8769 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_df.to_parquet(\"../../datax/treatments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_df = pd.read_parquet(\"../../datax/treatments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'treatments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test = load_dataset(\u001b[43mtreatments\u001b[49m, cache_dir=\u001b[33m\"\u001b[39m\u001b[33m../../datax\u001b[39m\u001b[33m\"\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'treatments' is not defined"
     ]
    }
   ],
   "source": [
    "test = load_dataset(treatments, cache_dir=\"../../datax\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['commit_id', 'code', 'repo', 'documentation', 'id', 'w_n_ast_errors', 'w_ast_errors', 'w_vocab_size', 'd_id', 'commit_message', 'fun_name', 'w_n_identifiers', 'w_nloc', 'random_cut', 'w_n_ast_nodes', 'w_token_counts', 'file_name', 'path', 'w_complexity', 'w_n_words', 'w_ast_levels', 'url', 'language', 'w_n_whitespaces', 'e_n_whitespaces', 'e_n_words', 'e_prediction', 'e_vocab_size', 'i_n_whitespaces', 'i_n_words', 'i_template', 'i_vocab_size', 'i_binary_treatment', 'i_treatment', 'y_lev', 'propensity_score', 'strata', 'dbar', 'd_y', 'dbar_y'],\n",
       "        num_rows: 8769\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_format(type='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_df = test['train'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_token_counts</th>\n",
       "      <th>file_name</th>\n",
       "      <th>d_id</th>\n",
       "      <th>w_n_ast_errors</th>\n",
       "      <th>documentation</th>\n",
       "      <th>w_n_whitespaces</th>\n",
       "      <th>w_complexity</th>\n",
       "      <th>path</th>\n",
       "      <th>w_ast_levels</th>\n",
       "      <th>w_vocab_size</th>\n",
       "      <th>...</th>\n",
       "      <th>e_n_whitespaces</th>\n",
       "      <th>e_n_words</th>\n",
       "      <th>prediction</th>\n",
       "      <th>e_vocab_size</th>\n",
       "      <th>i_n_whitespaces</th>\n",
       "      <th>i_n_words</th>\n",
       "      <th>template</th>\n",
       "      <th>i_vocab_size</th>\n",
       "      <th>i_binary_treatment</th>\n",
       "      <th>i_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>groupby.py</td>\n",
       "      <td>40113</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        Return a rolling group...</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>pandas/core/groupby/groupby.py</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>Certainly! Here's the completed code:\\n\\n```py...</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>degree_seq.py</td>\n",
       "      <td>42064</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Returns a random graph with giv...</td>\n",
       "      <td>417</td>\n",
       "      <td>13</td>\n",
       "      <td>networkx/generators/degree_seq.py</td>\n",
       "      <td>17</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>526</td>\n",
       "      <td>332</td>\n",
       "      <td>Here is the completed python method:\\n\\n```pyt...</td>\n",
       "      <td>182</td>\n",
       "      <td>380</td>\n",
       "      <td>175</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>base.py</td>\n",
       "      <td>2897</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Write the evaluation results to...</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>mlflow/models/evaluation/base.py</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>exist_ok=True)</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>test_message_builder.py</td>\n",
       "      <td>18592</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Test that a generic issue type'...</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>tests/sentry/integrations/slack/test_message_b...</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"danger\"</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>50</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>ImageProcessor.py</td>\n",
       "      <td>42906</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "        apply your own functio...</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>xlib/image/ImageProcessor.py</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "      <td>```\\n        mask = mask.astype(bool)\\n       ...</td>\n",
       "      <td>28</td>\n",
       "      <td>86</td>\n",
       "      <td>38</td>\n",
       "      <td>Complete the following python method: ```{}```</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>33</td>\n",
       "      <td>sales_order_analysis.py</td>\n",
       "      <td>14521</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>erpnext/selling/report/sales_order_analysis/sa...</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>527</td>\n",
       "      <td>170</td>\n",
       "      <td>Sure! Here's the code without the comments, su...</td>\n",
       "      <td>122</td>\n",
       "      <td>148</td>\n",
       "      <td>188</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>134</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>31</td>\n",
       "      <td>inspect.py</td>\n",
       "      <td>55277</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': '\n",
       "    Get the mapping of corouti...</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>python3.10.4/Lib/inspect.py</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>55</td>\n",
       "      <td>Certainly! Here's the code for the `getcorouti...</td>\n",
       "      <td>41</td>\n",
       "      <td>112</td>\n",
       "      <td>83</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>39</td>\n",
       "      <td>forwardprop_test.py</td>\n",
       "      <td>80975</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Computes the full Hessian matri...</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>keras/integration_test/forwardprop_test.py</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>87</td>\n",
       "      <td>Sure! Here's the code for the `_forward_over_b...</td>\n",
       "      <td>65</td>\n",
       "      <td>243</td>\n",
       "      <td>150</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>204</td>\n",
       "      <td>_stochastic_gradient.py</td>\n",
       "      <td>75837</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Probability estimates.\n",
       "\n",
       "       ...</td>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>sklearn/linear_model/_stochastic_gradient.py</td>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>374</td>\n",
       "      <td>116</td>\n",
       "      <td>Certainly! Here's the code without comments, s...</td>\n",
       "      <td>78</td>\n",
       "      <td>846</td>\n",
       "      <td>274</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>180</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>122</td>\n",
       "      <td>utils.py</td>\n",
       "      <td>5027</td>\n",
       "      <td>0</td>\n",
       "      <td>{'docstring': 'Fetch JSON Web Key Sets from a ...</td>\n",
       "      <td>216</td>\n",
       "      <td>5</td>\n",
       "      <td>saleor/plugins/openid_connect/utils.py</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>88</td>\n",
       "      <td>Sure, here is the `fetch_jwks` function withou...</td>\n",
       "      <td>62</td>\n",
       "      <td>255</td>\n",
       "      <td>129</td>\n",
       "      <td>Remeber you have a Python function named {}, t...</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8769 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w_token_counts                file_name   d_id  w_n_ast_errors  \\\n",
       "0                 48               groupby.py  40113               0   \n",
       "1                240            degree_seq.py  42064               0   \n",
       "2                153                  base.py   2897               0   \n",
       "3                137  test_message_builder.py  18592               0   \n",
       "4                 82        ImageProcessor.py  42906               0   \n",
       "...              ...                      ...    ...             ...   \n",
       "8764              33  sales_order_analysis.py  14521               0   \n",
       "8765              31               inspect.py  55277               0   \n",
       "8766              39      forwardprop_test.py  80975               0   \n",
       "8767             204  _stochastic_gradient.py  75837               0   \n",
       "8768             122                 utils.py   5027               0   \n",
       "\n",
       "                                          documentation  w_n_whitespaces  \\\n",
       "0     {'docstring': '\n",
       "        Return a rolling group...              101   \n",
       "1     {'docstring': 'Returns a random graph with giv...              417   \n",
       "2     {'docstring': 'Write the evaluation results to...              208   \n",
       "3     {'docstring': 'Test that a generic issue type'...              154   \n",
       "4     {'docstring': '\n",
       "        apply your own functio...              127   \n",
       "...                                                 ...              ...   \n",
       "8764  {'docstring': '\n",
       "\t\tSELECT\n",
       "\t\t\tso.transaction_dat...                5   \n",
       "8765  {'docstring': '\n",
       "    Get the mapping of corouti...              140   \n",
       "8766  {'docstring': 'Computes the full Hessian matri...               51   \n",
       "8767  {'docstring': 'Probability estimates.\n",
       "\n",
       "       ...              603   \n",
       "8768  {'docstring': 'Fetch JSON Web Key Sets from a ...              216   \n",
       "\n",
       "      w_complexity                                               path  \\\n",
       "0                1                     pandas/core/groupby/groupby.py   \n",
       "1               13                  networkx/generators/degree_seq.py   \n",
       "2                3                   mlflow/models/evaluation/base.py   \n",
       "3                1  tests/sentry/integrations/slack/test_message_b...   \n",
       "4                3                       xlib/image/ImageProcessor.py   \n",
       "...            ...                                                ...   \n",
       "8764             1  erpnext/selling/report/sales_order_analysis/sa...   \n",
       "8765             2                        python3.10.4/Lib/inspect.py   \n",
       "8766             1         keras/integration_test/forwardprop_test.py   \n",
       "8767             6       sklearn/linear_model/_stochastic_gradient.py   \n",
       "8768             5             saleor/plugins/openid_connect/utils.py   \n",
       "\n",
       "      w_ast_levels  w_vocab_size  ... e_n_whitespaces  e_n_words  \\\n",
       "0                9            17  ...              77         72   \n",
       "1               17            97  ...             526        332   \n",
       "2               13            36  ...               0          1   \n",
       "3               12            38  ...               0          1   \n",
       "4               13            34  ...              76         32   \n",
       "...            ...           ...  ...             ...        ...   \n",
       "8764            11            13  ...             527        170   \n",
       "8765             9            33  ...              73         55   \n",
       "8766             9            13  ...             143         87   \n",
       "8767            17            85  ...             374        116   \n",
       "8768            12            59  ...             198         88   \n",
       "\n",
       "                                             prediction e_vocab_size  \\\n",
       "0     Certainly! Here's the completed code:\\n\\n```py...           53   \n",
       "1     Here is the completed python method:\\n\\n```pyt...          182   \n",
       "2                                        exist_ok=True)            1   \n",
       "3                                              \"danger\"            1   \n",
       "4     ```\\n        mask = mask.astype(bool)\\n       ...           28   \n",
       "...                                                 ...          ...   \n",
       "8764  Sure! Here's the code without the comments, su...          122   \n",
       "8765  Certainly! Here's the code for the `getcorouti...           41   \n",
       "8766  Sure! Here's the code for the `_forward_over_b...           65   \n",
       "8767  Certainly! Here's the code without comments, s...           78   \n",
       "8768  Sure, here is the `fetch_jwks` function withou...           62   \n",
       "\n",
       "     i_n_whitespaces  i_n_words  \\\n",
       "0                 29         16   \n",
       "1                380        175   \n",
       "2                 23          9   \n",
       "3                152         50   \n",
       "4                 86         38   \n",
       "...              ...        ...   \n",
       "8764             148        188   \n",
       "8765             112         83   \n",
       "8766             243        150   \n",
       "8767             846        274   \n",
       "8768             255        129   \n",
       "\n",
       "                                               template i_vocab_size  \\\n",
       "0        Complete the following python method: ```{}```           16   \n",
       "1        Complete the following python method: ```{}```          100   \n",
       "2        Complete the following python method: ```{}```            9   \n",
       "3        Complete the following python method: ```{}```           38   \n",
       "4        Complete the following python method: ```{}```           34   \n",
       "...                                                 ...          ...   \n",
       "8764  Remeber you have a Python function named {}, t...          134   \n",
       "8765  Remeber you have a Python function named {}, t...           65   \n",
       "8766  Remeber you have a Python function named {}, t...          104   \n",
       "8767  Remeber you have a Python function named {}, t...          180   \n",
       "8768  Remeber you have a Python function named {}, t...           89   \n",
       "\n",
       "      i_binary_treatment i_treatment  \n",
       "0                  False     control  \n",
       "1                  False     control  \n",
       "2                  False     control  \n",
       "3                  False     control  \n",
       "4                  False     control  \n",
       "...                  ...         ...  \n",
       "8764                True          T2  \n",
       "8765                True          T2  \n",
       "8766                True          T2  \n",
       "8767                True          T2  \n",
       "8768                True          T2  \n",
       "\n",
       "[8769 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associational Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "from json import loads, dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(row):\n",
    "    return lev(row['code'].strip(), row['prediction'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_df['y_po_lev'] = treatments_df.apply(calculate_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">y_po_lev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>703.023948</td>\n",
       "      <td>581.868063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369.5</td>\n",
       "      <td>577.0</td>\n",
       "      <td>857.5</td>\n",
       "      <td>10919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>490.223401</td>\n",
       "      <td>556.738150</td>\n",
       "      <td>4.0</td>\n",
       "      <td>205.5</td>\n",
       "      <td>349.0</td>\n",
       "      <td>571.5</td>\n",
       "      <td>12311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>591.967157</td>\n",
       "      <td>574.681895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>767.5</td>\n",
       "      <td>10913.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_po_lev                                                    \\\n",
       "               count        mean         std  min    25%    50%    75%   \n",
       "i_treatment                                                              \n",
       "T1            2923.0  703.023948  581.868063  0.0  369.5  577.0  857.5   \n",
       "T2            2923.0  490.223401  556.738150  4.0  205.5  349.0  571.5   \n",
       "control       2923.0  591.967157  574.681895  0.0  243.0  464.0  767.5   \n",
       "\n",
       "                      \n",
       "                 max  \n",
       "i_treatment           \n",
       "T1           10919.0  \n",
       "T2           12311.0  \n",
       "control      10913.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df[['y_po_lev','i_treatment']].groupby('i_treatment').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CodeBLEU is a popular metric for measuring the model performance for a complete evaluation dataset, we are measuring distance for each sequence so CodeBLEU is not reported on the final analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_strings(row):\n",
    "    # Vectorize the strings using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    str1=row['code'].strip()\n",
    "    str2=row['prediction'].strip()\n",
    "    tfidf_matrix = vectorizer.fit_transform([str1, str2])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    \n",
    "    return cosine_sim[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_df['y_po_cos'] = treatments_df.apply(cosine_similarity_strings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.473827\n",
       "1       0.810686\n",
       "2       0.058783\n",
       "3       0.000000\n",
       "4       0.618505\n",
       "          ...   \n",
       "8764    0.106711\n",
       "8765    0.199285\n",
       "8766    0.421444\n",
       "8767    0.814839\n",
       "8768    0.917108\n",
       "Name: y_po_cos, Length: 8769, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df['y_po_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">y_po_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>0.433825</td>\n",
       "      <td>0.241293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258024</td>\n",
       "      <td>0.422385</td>\n",
       "      <td>0.588639</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>0.576346</td>\n",
       "      <td>0.258105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374087</td>\n",
       "      <td>0.580625</td>\n",
       "      <td>0.799039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>0.525883</td>\n",
       "      <td>0.249243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338401</td>\n",
       "      <td>0.508177</td>\n",
       "      <td>0.721361</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_po_cos                                                         \\\n",
       "               count      mean       std  min       25%       50%       75%   \n",
       "i_treatment                                                                   \n",
       "T1            2923.0  0.433825  0.241293  0.0  0.258024  0.422385  0.588639   \n",
       "T2            2923.0  0.576346  0.258105  0.0  0.374087  0.580625  0.799039   \n",
       "control       2923.0  0.525883  0.249243  0.0  0.338401  0.508177  0.721361   \n",
       "\n",
       "                  \n",
       "             max  \n",
       "i_treatment       \n",
       "T1           1.0  \n",
       "T2           1.0  \n",
       "control      1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df[['y_po_cos','i_treatment']].groupby('i_treatment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='i_treatment', ylabel='y_po_cos'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=treatments_df[['y_po_cos','i_treatment']], x=\"i_treatment\", y=\"y_po_cos\",showfliers=False, palette=\"Set2\", hue=\"i_treatment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeBLEU per treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebleu import calc_codebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_codeBLEU(row):\n",
    "    str1=row['code'].strip()\n",
    "    str2=row['prediction'].strip()\n",
    "    return calc_codebleu([str1], [str2], lang=\"python\", weights=(0.25, 0.25, 0.25, 0.25), tokenizer=None)['codebleu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n",
      "WARNING:root:WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.\n"
     ]
    }
   ],
   "source": [
    "treatments_df['y_po_codeBLEU']=treatments_df.apply(calculate_codeBLEU, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.528323\n",
       "1       0.700584\n",
       "2       0.004686\n",
       "3       0.250000\n",
       "4       0.223042\n",
       "          ...   \n",
       "8764    0.430092\n",
       "8765    0.369647\n",
       "8766    0.400655\n",
       "8767    0.570918\n",
       "8768    0.862230\n",
       "Name: y_po_codeBLEU, Length: 8769, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df['y_po_codeBLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">y_po_codeBLEU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>0.457055</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.283328</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>0.630582</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>0.485788</td>\n",
       "      <td>0.216197</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.320406</td>\n",
       "      <td>0.465267</td>\n",
       "      <td>0.631972</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>2923.0</td>\n",
       "      <td>0.477646</td>\n",
       "      <td>0.228582</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.291803</td>\n",
       "      <td>0.483273</td>\n",
       "      <td>0.658093</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_po_codeBLEU                                                    \\\n",
       "                    count      mean       std       min       25%       50%   \n",
       "i_treatment                                                                   \n",
       "T1                 2923.0  0.457055  0.213992  0.001808  0.283328  0.470511   \n",
       "T2                 2923.0  0.485788  0.216197  0.015306  0.320406  0.465267   \n",
       "control            2923.0  0.477646  0.228582  0.004686  0.291803  0.483273   \n",
       "\n",
       "                            \n",
       "                  75%  max  \n",
       "i_treatment                 \n",
       "T1           0.630582  1.0  \n",
       "T2           0.631972  1.0  \n",
       "control      0.658093  1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df[['y_po_codeBLEU','i_treatment']].groupby('i_treatment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='i_treatment', ylabel='y_po_codeBLEU'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=treatments_df[['y_po_codeBLEU','i_treatment']], x=\"i_treatment\", y=\"y_po_codeBLEU\",showfliers=False, palette=\"Set2\",hue=\"i_treatment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more input prompt size is close to the GT, the less distance outcome, gt\n",
    "\n",
    "We expect the following behavior in continues treatments: The more difference lev difference between prompts (i.e. control vs T1, T1 vs T2), the less difference at the potential outcome. We expect a negative correlations or causal effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounders =['w_ast_levels','w_n_whitespaces','w_complexity','w_nloc','w_token_counts','w_n_ast_nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_ast_levels w_ast_levels PearsonRResult(statistic=np.float64(0.9999999999999999), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.9999999999999998), pvalue=np.float64(0.0))\n",
      "w_ast_levels w_n_whitespaces PearsonRResult(statistic=np.float64(0.4990961343555267), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.6822881300127996), pvalue=np.float64(0.0))\n",
      "w_ast_levels w_complexity PearsonRResult(statistic=np.float64(0.5287915178516047), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5856303844701728), pvalue=np.float64(0.0))\n",
      "w_ast_levels w_nloc PearsonRResult(statistic=np.float64(0.44719445198749247), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5775515581247451), pvalue=np.float64(0.0))\n",
      "w_ast_levels w_token_counts PearsonRResult(statistic=np.float64(0.5270006805549071), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.6785033697899441), pvalue=np.float64(0.0))\n",
      "w_ast_levels w_n_ast_nodes PearsonRResult(statistic=np.float64(0.5993442827736034), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.7326915001787035), pvalue=np.float64(0.0))\n",
      "w_n_whitespaces w_ast_levels PearsonRResult(statistic=np.float64(0.4990961343555267), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.6822881300127996), pvalue=np.float64(0.0))\n",
      "w_n_whitespaces w_n_whitespaces PearsonRResult(statistic=np.float64(0.9999999999999999), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(1.0), pvalue=np.float64(0.0))\n",
      "w_n_whitespaces w_complexity PearsonRResult(statistic=np.float64(0.4520977501719116), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.552382982617644), pvalue=np.float64(0.0))\n",
      "w_n_whitespaces w_nloc PearsonRResult(statistic=np.float64(0.7877525039759078), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.7529821190256041), pvalue=np.float64(0.0))\n",
      "w_n_whitespaces w_token_counts PearsonRResult(statistic=np.float64(0.7357216906875989), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.8101423364901171), pvalue=np.float64(0.0))\n",
      "w_n_whitespaces w_n_ast_nodes PearsonRResult(statistic=np.float64(0.7899808396825204), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.8662016713119962), pvalue=np.float64(0.0))\n",
      "w_complexity w_ast_levels PearsonRResult(statistic=np.float64(0.5287915178516048), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5856303844701728), pvalue=np.float64(0.0))\n",
      "w_complexity w_n_whitespaces PearsonRResult(statistic=np.float64(0.4520977501719116), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.552382982617644), pvalue=np.float64(0.0))\n",
      "w_complexity w_complexity PearsonRResult(statistic=np.float64(1.0), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(1.0), pvalue=np.float64(0.0))\n",
      "w_complexity w_nloc PearsonRResult(statistic=np.float64(0.5576761593767621), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5229865546594921), pvalue=np.float64(0.0))\n",
      "w_complexity w_token_counts PearsonRResult(statistic=np.float64(0.6507208202748834), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5764542068763482), pvalue=np.float64(0.0))\n",
      "w_complexity w_n_ast_nodes PearsonRResult(statistic=np.float64(0.5723084535866328), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5430243412783181), pvalue=np.float64(0.0))\n",
      "w_nloc w_ast_levels PearsonRResult(statistic=np.float64(0.4471944519874925), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5775515581247451), pvalue=np.float64(0.0))\n",
      "w_nloc w_n_whitespaces PearsonRResult(statistic=np.float64(0.7877525039759077), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.7529821190256042), pvalue=np.float64(0.0))\n",
      "w_nloc w_complexity PearsonRResult(statistic=np.float64(0.5576761593767621), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5229865546594921), pvalue=np.float64(0.0))\n",
      "w_nloc w_nloc PearsonRResult(statistic=np.float64(1.0), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(1.0), pvalue=np.float64(0.0))\n",
      "w_nloc w_token_counts PearsonRResult(statistic=np.float64(0.8536058035354178), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.8466424007951175), pvalue=np.float64(0.0))\n",
      "w_nloc w_n_ast_nodes PearsonRResult(statistic=np.float64(0.7845496940809744), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.7799867853721003), pvalue=np.float64(0.0))\n",
      "w_token_counts w_ast_levels PearsonRResult(statistic=np.float64(0.5270006805549071), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.678503369789944), pvalue=np.float64(0.0))\n",
      "w_token_counts w_n_whitespaces PearsonRResult(statistic=np.float64(0.7357216906875989), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.8101423364901171), pvalue=np.float64(0.0))\n",
      "w_token_counts w_complexity PearsonRResult(statistic=np.float64(0.6507208202748834), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5764542068763481), pvalue=np.float64(0.0))\n",
      "w_token_counts w_nloc PearsonRResult(statistic=np.float64(0.8536058035354178), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.8466424007951175), pvalue=np.float64(0.0))\n",
      "w_token_counts w_token_counts PearsonRResult(statistic=np.float64(1.0), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(1.0), pvalue=np.float64(0.0))\n",
      "w_token_counts w_n_ast_nodes PearsonRResult(statistic=np.float64(0.9218749907899798), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.9234918828276372), pvalue=np.float64(0.0))\n",
      "w_n_ast_nodes w_ast_levels PearsonRResult(statistic=np.float64(0.5993442827736034), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.7326915001787037), pvalue=np.float64(0.0))\n",
      "w_n_ast_nodes w_n_whitespaces PearsonRResult(statistic=np.float64(0.7899808396825202), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.8662016713119961), pvalue=np.float64(0.0))\n",
      "w_n_ast_nodes w_complexity PearsonRResult(statistic=np.float64(0.5723084535866328), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.5430243412783182), pvalue=np.float64(0.0))\n",
      "w_n_ast_nodes w_nloc PearsonRResult(statistic=np.float64(0.7845496940809744), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.7799867853721003), pvalue=np.float64(0.0))\n",
      "w_n_ast_nodes w_token_counts PearsonRResult(statistic=np.float64(0.9218749907899798), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(0.9234918828276371), pvalue=np.float64(0.0))\n",
      "w_n_ast_nodes w_n_ast_nodes PearsonRResult(statistic=np.float64(0.9999999999999997), pvalue=np.float64(0.0)) SignificanceResult(statistic=np.float64(1.0), pvalue=np.float64(0.0))\n"
     ]
    }
   ],
   "source": [
    "for z0,z1 in itertools.product(confounders,confounders):\n",
    "    #print(z1)\n",
    "    tmp= stats.pearsonr(treatments_df[z0],treatments_df[z1])\n",
    "    spermanr = stats.spearmanr(treatments_df[z0],treatments_df[z1])\n",
    "    print(z0,z1,tmp, spermanr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['w_token_counts',\n",
    " 'w_n_ast_errors',\n",
    " 'w_n_whitespaces',\n",
    " 'w_complexity',\n",
    " 'w_ast_levels',\n",
    " 'w_vocab_size',\n",
    " 'w_nloc',\n",
    " 'w_n_ast_nodes',\n",
    " 'w_n_identifiers',\n",
    " 'w_n_words',\n",
    " 'e_n_whitespaces',\n",
    " 'e_n_words',\n",
    " 'e_vocab_size',\n",
    " 'i_n_whitespaces',\n",
    " 'i_n_words',\n",
    " 'i_vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=list()\n",
    "for z0,z1 in itertools.product(variables,variables):\n",
    "    #print(z1)\n",
    "    p_correlation= stats.pearsonr(treatments_df[z0],treatments_df[z1]).correlation\n",
    "    s_correlation = stats.spearmanr(treatments_df[z0],treatments_df[z1]).correlation\n",
    "    p_pvalue= stats.pearsonr(treatments_df[z0],treatments_df[z1]).pvalue\n",
    "    s_pvalue = stats.spearmanr(treatments_df[z0],treatments_df[z1]).pvalue\n",
    "    result = [z0,z1,p_correlation, p_pvalue, s_correlation, s_pvalue]\n",
    "    total.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['w_token_counts',\n",
       "  'w_token_counts',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.19243291704495993),\n",
       "  np.float64(6.465788564807214e-74),\n",
       "  np.float64(-0.006175438014218626),\n",
       "  np.float64(0.5631228622316575)],\n",
       " ['w_token_counts',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.7357216906875989),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8101423364901171),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_complexity',\n",
       "  np.float64(0.6507208202748834),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5764542068763481),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.5270006805549071),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.678503369789944),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.7561435643892088),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8375058678828599),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_nloc',\n",
       "  np.float64(0.8536058035354178),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8466424007951175),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.9218749907899798),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9234918828276372),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.7591464722668152),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8535040680934153),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'w_n_words',\n",
       "  np.float64(0.814008792339278),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8570717594710896),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.5670732446468155),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5102688149832127),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'e_n_words',\n",
       "  np.float64(0.38040402375522114),\n",
       "  np.float64(5.959553720780655e-300),\n",
       "  np.float64(0.35704589738009834),\n",
       "  np.float64(5.787577252416711e-262)],\n",
       " ['w_token_counts',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.34087248113646157),\n",
       "  np.float64(1.791022551291699e-237),\n",
       "  np.float64(0.3482939178534328),\n",
       "  np.float64(1.5661616045651993e-248)],\n",
       " ['w_token_counts',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.5962543989652713),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5484095268529942),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'i_n_words',\n",
       "  np.float64(0.4661975474024565),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.47745995826137977),\n",
       "  np.float64(0.0)],\n",
       " ['w_token_counts',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.44065840470881146),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4715663975722653),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.19243291704495993),\n",
       "  np.float64(6.465788564807214e-74),\n",
       "  np.float64(-0.006175438014218626),\n",
       "  np.float64(0.5631228622316575)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9999999999999998),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(-0.026714604209341165),\n",
       "  np.float64(0.01235902762197192),\n",
       "  np.float64(-0.056116702354795246),\n",
       "  np.float64(1.4537155506435077e-07)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_complexity',\n",
       "  np.float64(0.21529710329702176),\n",
       "  np.float64(1.747894420251479e-92),\n",
       "  np.float64(-0.04588858183715512),\n",
       "  np.float64(1.717303422736975e-05)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_ast_levels',\n",
       "  np.float64(-0.026913332480235832),\n",
       "  np.float64(0.011724127341927676),\n",
       "  np.float64(-0.015982102812411365),\n",
       "  np.float64(0.1345251541916348)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_vocab_size',\n",
       "  np.float64(-0.0014219954385747949),\n",
       "  np.float64(0.8940819365941522),\n",
       "  np.float64(0.043522004351432775),\n",
       "  np.float64(4.56442191671693e-05)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_nloc',\n",
       "  np.float64(0.19706364202562354),\n",
       "  np.float64(1.7033638773947226e-77),\n",
       "  np.float64(-0.015424256421194733),\n",
       "  np.float64(0.14866790499912305)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.03289683527731477),\n",
       "  np.float64(0.002063405996624037),\n",
       "  np.float64(0.05507697224483302),\n",
       "  np.float64(2.4596041877008196e-07)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.16224528665167443),\n",
       "  np.float64(8.594856493811477e-53),\n",
       "  np.float64(0.08798439936918626),\n",
       "  np.float64(1.5323893710156398e-16)],\n",
       " ['w_n_ast_errors',\n",
       "  'w_n_words',\n",
       "  np.float64(-0.006193425526774746),\n",
       "  np.float64(0.5619864729076206),\n",
       "  np.float64(0.03333228346491916),\n",
       "  np.float64(0.0017977623386437728)],\n",
       " ['w_n_ast_errors',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.01018635663702321),\n",
       "  np.float64(0.3402005177178452),\n",
       "  np.float64(0.0020927679243293107),\n",
       "  np.float64(0.8446530459048818)],\n",
       " ['w_n_ast_errors',\n",
       "  'e_n_words',\n",
       "  np.float64(0.03556791456214932),\n",
       "  np.float64(0.000864528154016306),\n",
       "  np.float64(0.02258309947248789),\n",
       "  np.float64(0.034454159991078696)],\n",
       " ['w_n_ast_errors',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.039337538778224684),\n",
       "  np.float64(0.0002290767573875307),\n",
       "  np.float64(0.031074422860399426),\n",
       "  np.float64(0.003612111865458417)],\n",
       " ['w_n_ast_errors',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(-0.006270023464504975),\n",
       "  np.float64(0.5571597220133419),\n",
       "  np.float64(-0.027333328883419272),\n",
       "  np.float64(0.010476660630158065)],\n",
       " ['w_n_ast_errors',\n",
       "  'i_n_words',\n",
       "  np.float64(0.026971728572193668),\n",
       "  np.float64(0.01154314507902686),\n",
       "  np.float64(0.030499100768681175),\n",
       "  np.float64(0.0042863330511987265)],\n",
       " ['w_n_ast_errors',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.02701923365697489),\n",
       "  np.float64(0.01139774940279815),\n",
       "  np.float64(0.03120036263957241),\n",
       "  np.float64(0.003478044224510393)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.7357216906875989),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8101423364901171),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(-0.026714604209341165),\n",
       "  np.float64(0.01235902762197192),\n",
       "  np.float64(-0.05611670235479526),\n",
       "  np.float64(1.4537155506434945e-07)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.9999999999999999),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_complexity',\n",
       "  np.float64(0.4520977501719116),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.552382982617644),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.4990961343555267),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6822881300127996),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.6645662455492254),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8852899630392149),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_nloc',\n",
       "  np.float64(0.7877525039759078),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7529821190256041),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.7899808396825204),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8662016713119962),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.5497467507388487),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.77760078228694),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'w_n_words',\n",
       "  np.float64(0.7545405682512193),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8974345293025542),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.760419829557472),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5022567308757648),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'e_n_words',\n",
       "  np.float64(0.3122521915572819),\n",
       "  np.float64(1.3657405226211848e-197),\n",
       "  np.float64(0.3110540411491128),\n",
       "  np.float64(5.148879785189463e-196)],\n",
       " ['w_n_whitespaces',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.24992471583820075),\n",
       "  np.float64(5.552230875591728e-125),\n",
       "  np.float64(0.3000647671265144),\n",
       "  np.float64(6.751879545148911e-182)],\n",
       " ['w_n_whitespaces',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.8162022175137895),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6666910856063926),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'i_n_words',\n",
       "  np.float64(0.3984232096795318),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4831313822728238),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_whitespaces',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.3570432489558609),\n",
       "  np.float64(5.842872470064653e-262),\n",
       "  np.float64(0.47997494414372643),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.6507208202748834),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5764542068763482),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.21529710329702176),\n",
       "  np.float64(1.747894420251479e-92),\n",
       "  np.float64(-0.04588858183715512),\n",
       "  np.float64(1.717303422736975e-05)],\n",
       " ['w_complexity',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.4520977501719116),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.552382982617644),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_complexity',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.5287915178516048),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5856303844701728),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.6325317173487343),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.593000069121981),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_nloc',\n",
       "  np.float64(0.5576761593767621),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5229865546594921),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.5723084535866328),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5430243412783181),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.5301995041044169),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.46270603504392754),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'w_n_words',\n",
       "  np.float64(0.648218207719039),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6103058781014912),\n",
       "  np.float64(0.0)],\n",
       " ['w_complexity',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.3216738536245097),\n",
       "  np.float64(3.0334552592709887e-210),\n",
       "  np.float64(0.3742853801281313),\n",
       "  np.float64(1.0782624494735928e-289)],\n",
       " ['w_complexity',\n",
       "  'e_n_words',\n",
       "  np.float64(0.3072852859526205),\n",
       "  np.float64(4.190682509214775e-191),\n",
       "  np.float64(0.2734766478441396),\n",
       "  np.float64(3.2246474266071905e-150)],\n",
       " ['w_complexity',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.2709268150383519),\n",
       "  np.float64(2.326242065173933e-147),\n",
       "  np.float64(0.2489887219065404),\n",
       "  np.float64(4.944103699853044e-124)],\n",
       " ['w_complexity',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.3301780681499282),\n",
       "  np.float64(4.599953061782032e-222),\n",
       "  np.float64(0.37311898483442696),\n",
       "  np.float64(9.185084275076665e-288)],\n",
       " ['w_complexity',\n",
       "  'i_n_words',\n",
       "  np.float64(0.37156162615436134),\n",
       "  np.float64(3.373432845809345e-285),\n",
       "  np.float64(0.35324393134031146),\n",
       "  np.float64(4.468890820878274e-256)],\n",
       " ['w_complexity',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.3698856612386199),\n",
       "  np.float64(1.8733299414234357e-282),\n",
       "  np.float64(0.3471667045967565),\n",
       "  np.float64(7.832752125756156e-247)],\n",
       " ['w_ast_levels',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.5270006805549071),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6785033697899441),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(-0.02691333248023583),\n",
       "  np.float64(0.011724127341927676),\n",
       "  np.float64(-0.015982102812411365),\n",
       "  np.float64(0.1345251541916348)],\n",
       " ['w_ast_levels',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.4990961343555267),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6822881300127996),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_complexity',\n",
       "  np.float64(0.5287915178516047),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5856303844701728),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.9999999999999999),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9999999999999998),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.6079231516744814),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6761616831230379),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_nloc',\n",
       "  np.float64(0.44719445198749247),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5775515581247451),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.5993442827736034),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7326915001787035),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.607856223035797),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6748645126014037),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'w_n_words',\n",
       "  np.float64(0.5724544220071908),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6755834327850319),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.3898379176770721),\n",
       "  np.float64(3.32523284e-316),\n",
       "  np.float64(0.4110417597634477),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'e_n_words',\n",
       "  np.float64(0.27907125067925975),\n",
       "  np.float64(1.343933497167525e-156),\n",
       "  np.float64(0.26329741464467776),\n",
       "  np.float64(5.4269428876234896e-139)],\n",
       " ['w_ast_levels',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.2768588934974741),\n",
       "  np.float64(4.6699655641668314e-154),\n",
       "  np.float64(0.26070331795823226),\n",
       "  np.float64(3.291013377008714e-136)],\n",
       " ['w_ast_levels',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.3703949996998294),\n",
       "  np.float64(2.7558466691178907e-283),\n",
       "  np.float64(0.43746692611339455),\n",
       "  np.float64(0.0)],\n",
       " ['w_ast_levels',\n",
       "  'i_n_words',\n",
       "  np.float64(0.3089852309067529),\n",
       "  np.float64(2.607758478347649e-193),\n",
       "  np.float64(0.3582279529335334),\n",
       "  np.float64(8.230089132646972e-264)],\n",
       " ['w_ast_levels',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.3302646504115752),\n",
       "  np.float64(3.471009545346545e-222),\n",
       "  np.float64(0.3602639731468211),\n",
       "  np.float64(5.192471947474459e-267)],\n",
       " ['w_vocab_size',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.7561435643892088),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8375058678828599),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(-0.0014219954385747936),\n",
       "  np.float64(0.8940819365941522),\n",
       "  np.float64(0.043522004351432775),\n",
       "  np.float64(4.56442191671693e-05)],\n",
       " ['w_vocab_size',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.6645662455492254),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8852899630392149),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_complexity',\n",
       "  np.float64(0.6325317173487343),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.593000069121981),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.6079231516744814),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6761616831230379),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_vocab_size',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_nloc',\n",
       "  np.float64(0.6428947122493258),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7510544655741759),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.8436219495427355),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9061590804702223),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.8078116381495783),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8275259846880286),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'w_n_words',\n",
       "  np.float64(0.9560728157110109),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9879795733556364),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.46825990227352865),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5151193076879514),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'e_n_words',\n",
       "  np.float64(0.40757475140814226),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.3653004039185452),\n",
       "  np.float64(4.991471081811902e-275)],\n",
       " ['w_vocab_size',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.4024488583609285),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.3632729494628876),\n",
       "  np.float64(8.770362586651322e-272)],\n",
       " ['w_vocab_size',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.5019743068575309),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5916864228596775),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'i_n_words',\n",
       "  np.float64(0.5299363870485871),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5411708015366777),\n",
       "  np.float64(0.0)],\n",
       " ['w_vocab_size',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.5523042907844735),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5445199998267021),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.8536058035354178),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8466424007951175),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.19706364202562354),\n",
       "  np.float64(1.7033638773947226e-77),\n",
       "  np.float64(-0.015424256421194733),\n",
       "  np.float64(0.14866790499912305)],\n",
       " ['w_nloc',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.7877525039759077),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7529821190256042),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_complexity',\n",
       "  np.float64(0.5576761593767621),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5229865546594921),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.4471944519874925),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5775515581247451),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.6428947122493258),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7510544655741758),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_nloc',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.7845496940809744),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7799867853721003),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.624042958343595),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7198322886308766),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'w_n_words',\n",
       "  np.float64(0.701485769815803),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7648115466624597),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.6397064258770416),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4996094804981535),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'e_n_words',\n",
       "  np.float64(0.33636032504522084),\n",
       "  np.float64(6.756398178713562e-231),\n",
       "  np.float64(0.33031906460880167),\n",
       "  np.float64(2.907871889481469e-222)],\n",
       " ['w_nloc',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.29775412467238876),\n",
       "  np.float64(5.2540685797045136e-179),\n",
       "  np.float64(0.3270831565247423),\n",
       "  np.float64(1.0190801515278838e-217)],\n",
       " ['w_nloc',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.6683247652977408),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5188769338767233),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'i_n_words',\n",
       "  np.float64(0.4201886578392034),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4372618026972731),\n",
       "  np.float64(0.0)],\n",
       " ['w_nloc',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.39460527303660003),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4353205574189013),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.9218749907899798),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9234918828276371),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.03289683527731476),\n",
       "  np.float64(0.002063405996624037),\n",
       "  np.float64(0.05507697224483302),\n",
       "  np.float64(2.4596041877008196e-07)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.7899808396825202),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8662016713119961),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_complexity',\n",
       "  np.float64(0.5723084535866328),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5430243412783182),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.5993442827736034),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7326915001787037),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.8436219495427355),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9061590804702222),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_nloc',\n",
       "  np.float64(0.7845496940809744),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7799867853721003),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.9999999999999997),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.8034183001519282),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9073978015773614),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'w_n_words',\n",
       "  np.float64(0.8954789419953444),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9234755378036216),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.5926228087235358),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5057841390057547),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'e_n_words',\n",
       "  np.float64(0.3937841663624979),\n",
       "  np.float64(4e-323),\n",
       "  np.float64(0.35279630770876935),\n",
       "  np.float64(2.178008683112619e-255)],\n",
       " ['w_n_ast_nodes',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.3565116123064391),\n",
       "  np.float64(3.9336072047063175e-261),\n",
       "  np.float64(0.34530773740095105),\n",
       "  np.float64(4.793936916330531e-244)],\n",
       " ['w_n_ast_nodes',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.630015091868017),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5796138633438634),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'i_n_words',\n",
       "  np.float64(0.5025739628471854),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5063145748881588),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_ast_nodes',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.4780327375826023),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4998976758143783),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.7591464722668152),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8535040680934154),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.16224528665167445),\n",
       "  np.float64(8.594856493811477e-53),\n",
       "  np.float64(0.08798439936918626),\n",
       "  np.float64(1.5323893710156398e-16)],\n",
       " ['w_n_identifiers',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.5497467507388487),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7776007822869401),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_complexity',\n",
       "  np.float64(0.5301995041044167),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4627060350439275),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.607856223035797),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6748645126014037),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.8078116381495783),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8275259846880285),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_nloc',\n",
       "  np.float64(0.624042958343595),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7198322886308766),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.8034183001519282),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9073978015773613),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.9999999999999998),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'w_n_words',\n",
       "  np.float64(0.7437421256360544),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8193256353355838),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.40871224248285215),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4582765507040158),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'e_n_words',\n",
       "  np.float64(0.3503533015298208),\n",
       "  np.float64(1.181761123760613e-251),\n",
       "  np.float64(0.320934890156163),\n",
       "  np.float64(3.097555130847909e-209)],\n",
       " ['w_n_identifiers',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.36915611164309475),\n",
       "  np.float64(2.898801059733938e-281),\n",
       "  np.float64(0.32828961312799076),\n",
       "  np.float64(2.0907381718574238e-219)],\n",
       " ['w_n_identifiers',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.4233697610687855),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5234867060019465),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'i_n_words',\n",
       "  np.float64(0.4227601785774302),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4525712442293984),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_identifiers',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.45402368917089),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4556677276032285),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.814008792339278),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8570717594710897),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(-0.006193425526774745),\n",
       "  np.float64(0.5619864729076206),\n",
       "  np.float64(0.03333228346491916),\n",
       "  np.float64(0.0017977623386437728)],\n",
       " ['w_n_words',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.7545405682512193),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8974345293025542),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_complexity',\n",
       "  np.float64(0.648218207719039),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6103058781014912),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.5724544220071908),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6755834327850317),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.9560728157110109),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9879795733556365),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_nloc',\n",
       "  np.float64(0.701485769815803),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.7648115466624595),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.8954789419953444),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9234755378036217),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.7437421256360544),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8193256353355839),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'w_n_words',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.5411762296819582),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5208105274306088),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'e_n_words',\n",
       "  np.float64(0.4211297586207482),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.36931501347619106),\n",
       "  np.float64(1.597261145149038e-281)],\n",
       " ['w_n_words',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.37888708258281006),\n",
       "  np.float64(2.1823468515535433e-297),\n",
       "  np.float64(0.356930621467112),\n",
       "  np.float64(8.753997061692866e-262)],\n",
       " ['w_n_words',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.5873636682854525),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5996507743271579),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'i_n_words',\n",
       "  np.float64(0.5576555203472524),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5477607666539643),\n",
       "  np.float64(0.0)],\n",
       " ['w_n_words',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.5379296732524539),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5419105841919781),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.5670732446468155),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5102688149832127),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.010186356637023213),\n",
       "  np.float64(0.3402005177178452),\n",
       "  np.float64(0.0020927679243293103),\n",
       "  np.float64(0.8446530459048818)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.760419829557472),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5022567308757648),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_complexity',\n",
       "  np.float64(0.3216738536245097),\n",
       "  np.float64(3.0334552592709887e-210),\n",
       "  np.float64(0.3742853801281313),\n",
       "  np.float64(1.0782624494735928e-289)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.3898379176770721),\n",
       "  np.float64(3.32523284e-316),\n",
       "  np.float64(0.4110417597634477),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.46825990227352865),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5151193076879514),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_nloc',\n",
       "  np.float64(0.6397064258770415),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.49960948049815346),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.5926228087235358),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5057841390057547),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.4087122424828521),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4582765507040158),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'w_n_words',\n",
       "  np.float64(0.5411762296819582),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5208105274306088),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'e_n_words',\n",
       "  np.float64(0.6761727267539888),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8785070937454584),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.60700825324538),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8548466163769821),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_whitespaces',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.710396939507975),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.3537914807291565),\n",
       "  np.float64(6.415970146991912e-257)],\n",
       " ['e_n_whitespaces',\n",
       "  'i_n_words',\n",
       "  np.float64(0.32548168950132544),\n",
       "  np.float64(1.7254032594534308e-215),\n",
       "  np.float64(0.2628046872599911),\n",
       "  np.float64(1.8430903128969317e-138)],\n",
       " ['e_n_whitespaces',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.28858585499600226),\n",
       "  np.float64(8.522306802507747e-168),\n",
       "  np.float64(0.2718798949110201),\n",
       "  np.float64(2.0042323154485205e-148)],\n",
       " ['e_n_words',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.38040402375522114),\n",
       "  np.float64(5.959553720780655e-300),\n",
       "  np.float64(0.35704589738009834),\n",
       "  np.float64(5.787577252416711e-262)],\n",
       " ['e_n_words',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.035567914562149326),\n",
       "  np.float64(0.000864528154016306),\n",
       "  np.float64(0.02258309947248789),\n",
       "  np.float64(0.034454159991078696)],\n",
       " ['e_n_words',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.3122521915572819),\n",
       "  np.float64(1.3657405226211848e-197),\n",
       "  np.float64(0.3110540411491127),\n",
       "  np.float64(5.148879785190342e-196)],\n",
       " ['e_n_words',\n",
       "  'w_complexity',\n",
       "  np.float64(0.3072852859526205),\n",
       "  np.float64(4.190682509214775e-191),\n",
       "  np.float64(0.2734766478441396),\n",
       "  np.float64(3.2246474266071905e-150)],\n",
       " ['e_n_words',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.27907125067925975),\n",
       "  np.float64(1.343933497167525e-156),\n",
       "  np.float64(0.26329741464467776),\n",
       "  np.float64(5.4269428876234896e-139)],\n",
       " ['e_n_words',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.40757475140814226),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.3653004039185452),\n",
       "  np.float64(4.991471081811902e-275)],\n",
       " ['e_n_words',\n",
       "  'w_nloc',\n",
       "  np.float64(0.33636032504522084),\n",
       "  np.float64(6.756398178713562e-231),\n",
       "  np.float64(0.3303190646088016),\n",
       "  np.float64(2.907871889481965e-222)],\n",
       " ['e_n_words',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.3937841663624979),\n",
       "  np.float64(4e-323),\n",
       "  np.float64(0.3527963077087693),\n",
       "  np.float64(2.178008683113858e-255)],\n",
       " ['e_n_words',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.3503533015298208),\n",
       "  np.float64(1.181761123760613e-251),\n",
       "  np.float64(0.320934890156163),\n",
       "  np.float64(3.097555130847909e-209)],\n",
       " ['e_n_words',\n",
       "  'w_n_words',\n",
       "  np.float64(0.4211297586207482),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.36931501347619106),\n",
       "  np.float64(1.597261145149038e-281)],\n",
       " ['e_n_words',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.6761727267539888),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8785070937454583),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_words',\n",
       "  'e_n_words',\n",
       "  np.float64(0.9999999999999999),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_words',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.9609733185846652),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9819700313368082),\n",
       "  np.float64(0.0)],\n",
       " ['e_n_words',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.27148286902856145),\n",
       "  np.float64(5.5718547819523435e-148),\n",
       "  np.float64(0.18940422015123337),\n",
       "  np.float64(1.2657935388455976e-71)],\n",
       " ['e_n_words',\n",
       "  'i_n_words',\n",
       "  np.float64(0.21015187120175433),\n",
       "  np.float64(4.1480647808039945e-88),\n",
       "  np.float64(0.15929274979489266),\n",
       "  np.float64(6.272114226109191e-51)],\n",
       " ['e_n_words',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.204187365146615),\n",
       "  np.float64(3.5160446506487054e-83),\n",
       "  np.float64(0.17111408661457464),\n",
       "  np.float64(1.3242818590259981e-58)],\n",
       " ['e_vocab_size',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.34087248113646157),\n",
       "  np.float64(1.791022551291699e-237),\n",
       "  np.float64(0.3482939178534328),\n",
       "  np.float64(1.5661616045651993e-248)],\n",
       " ['e_vocab_size',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.039337538778224684),\n",
       "  np.float64(0.0002290767573875307),\n",
       "  np.float64(0.031074422860399426),\n",
       "  np.float64(0.003612111865458417)],\n",
       " ['e_vocab_size',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.24992471583820075),\n",
       "  np.float64(5.552230875591728e-125),\n",
       "  np.float64(0.3000647671265144),\n",
       "  np.float64(6.751879545148911e-182)],\n",
       " ['e_vocab_size',\n",
       "  'w_complexity',\n",
       "  np.float64(0.2709268150383519),\n",
       "  np.float64(2.326242065173933e-147),\n",
       "  np.float64(0.2489887219065404),\n",
       "  np.float64(4.944103699853044e-124)],\n",
       " ['e_vocab_size',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.27685889349747406),\n",
       "  np.float64(4.6699655641668314e-154),\n",
       "  np.float64(0.2607033179582323),\n",
       "  np.float64(3.291013377008339e-136)],\n",
       " ['e_vocab_size',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.4024488583609284),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.36327294946288763),\n",
       "  np.float64(8.770362586649324e-272)],\n",
       " ['e_vocab_size',\n",
       "  'w_nloc',\n",
       "  np.float64(0.29775412467238876),\n",
       "  np.float64(5.2540685797045136e-179),\n",
       "  np.float64(0.3270831565247423),\n",
       "  np.float64(1.0190801515278838e-217)],\n",
       " ['e_vocab_size',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.3565116123064391),\n",
       "  np.float64(3.9336072047063175e-261),\n",
       "  np.float64(0.34530773740095105),\n",
       "  np.float64(4.793936916330531e-244)],\n",
       " ['e_vocab_size',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.36915611164309486),\n",
       "  np.float64(2.898801059733938e-281),\n",
       "  np.float64(0.32828961312799076),\n",
       "  np.float64(2.0907381718574238e-219)],\n",
       " ['e_vocab_size',\n",
       "  'w_n_words',\n",
       "  np.float64(0.37888708258281006),\n",
       "  np.float64(2.1823468515535433e-297),\n",
       "  np.float64(0.356930621467112),\n",
       "  np.float64(8.753997061692866e-262)],\n",
       " ['e_vocab_size',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.60700825324538),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8548466163769821),\n",
       "  np.float64(0.0)],\n",
       " ['e_vocab_size',\n",
       "  'e_n_words',\n",
       "  np.float64(0.9609733185846652),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.981970031336808),\n",
       "  np.float64(0.0)],\n",
       " ['e_vocab_size',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.9999999999999999),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['e_vocab_size',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.21636918861464752),\n",
       "  np.float64(2.0716087474499627e-93),\n",
       "  np.float64(0.20046160529070314),\n",
       "  np.float64(3.520734389034639e-80)],\n",
       " ['e_vocab_size',\n",
       "  'i_n_words',\n",
       "  np.float64(0.19615595992539334),\n",
       "  np.float64(8.7116152972719e-77),\n",
       "  np.float64(0.17537388549056182),\n",
       "  np.float64(1.6389954913454558e-61)],\n",
       " ['e_vocab_size',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.21736143405351974),\n",
       "  np.float64(2.848348287956501e-94),\n",
       "  np.float64(0.19370837606450161),\n",
       "  np.float64(6.821262484235549e-75)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.5962543989652713),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.548409526852994),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(-0.006270023464504971),\n",
       "  np.float64(0.5571597220133419),\n",
       "  np.float64(-0.027333328883419272),\n",
       "  np.float64(0.010476660630158065)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.8162022175137893),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.6666910856063926),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_complexity',\n",
       "  np.float64(0.3301780681499282),\n",
       "  np.float64(4.599953061782032e-222),\n",
       "  np.float64(0.37311898483442696),\n",
       "  np.float64(9.185084275076665e-288)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.3703949996998294),\n",
       "  np.float64(2.7558466691178907e-283),\n",
       "  np.float64(0.4374669261133945),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.5019743068575309),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5916864228596775),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_nloc',\n",
       "  np.float64(0.6683247652977408),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5188769338767233),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.630015091868017),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5796138633438633),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.4233697610687855),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5234867060019465),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'w_n_words',\n",
       "  np.float64(0.5873636682854525),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5996507743271579),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.710396939507975),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.3537914807291565),\n",
       "  np.float64(6.415970146991912e-257)],\n",
       " ['i_n_whitespaces',\n",
       "  'e_n_words',\n",
       "  np.float64(0.27148286902856145),\n",
       "  np.float64(5.5718547819523435e-148),\n",
       "  np.float64(0.18940422015123337),\n",
       "  np.float64(1.2657935388455976e-71)],\n",
       " ['i_n_whitespaces',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.21636918861464752),\n",
       "  np.float64(2.0716087474499627e-93),\n",
       "  np.float64(0.20046160529070314),\n",
       "  np.float64(3.520734389034639e-80)],\n",
       " ['i_n_whitespaces',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'i_n_words',\n",
       "  np.float64(0.7286702979134105),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8905803499178149),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_whitespaces',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.6730239502066849),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8832931717617204),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.4661975474024565),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.47745995826137977),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.026971728572193668),\n",
       "  np.float64(0.01154314507902686),\n",
       "  np.float64(0.030499100768681175),\n",
       "  np.float64(0.0042863330511987265)],\n",
       " ['i_n_words',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.3984232096795319),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.48313138227282376),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'w_complexity',\n",
       "  np.float64(0.37156162615436134),\n",
       "  np.float64(3.373432845809345e-285),\n",
       "  np.float64(0.35324393134031146),\n",
       "  np.float64(4.468890820878274e-256)],\n",
       " ['i_n_words',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.3089852309067529),\n",
       "  np.float64(2.607758478347649e-193),\n",
       "  np.float64(0.3582279529335333),\n",
       "  np.float64(8.230089132646972e-264)],\n",
       " ['i_n_words',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.529936387048587),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5411708015366777),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'w_nloc',\n",
       "  np.float64(0.4201886578392034),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4372618026972731),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.5025739628471854),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5063145748881588),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.4227601785774302),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4525712442293983),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'w_n_words',\n",
       "  np.float64(0.5576555203472523),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5477607666539643),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.32548168950132544),\n",
       "  np.float64(1.7254032594534308e-215),\n",
       "  np.float64(0.2628046872599911),\n",
       "  np.float64(1.8430903128969317e-138)],\n",
       " ['i_n_words',\n",
       "  'e_n_words',\n",
       "  np.float64(0.21015187120175433),\n",
       "  np.float64(4.1480647808039945e-88),\n",
       "  np.float64(0.15929274979489264),\n",
       "  np.float64(6.272114226109639e-51)],\n",
       " ['i_n_words',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.19615595992539334),\n",
       "  np.float64(8.7116152972719e-77),\n",
       "  np.float64(0.17537388549056182),\n",
       "  np.float64(1.6389954913454558e-61)],\n",
       " ['i_n_words',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.7286702979134105),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.890580349917815),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'i_n_words',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)],\n",
       " ['i_n_words',\n",
       "  'i_vocab_size',\n",
       "  np.float64(0.9688011573915183),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9916811718851848),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'w_token_counts',\n",
       "  np.float64(0.44065840470881146),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.47156639757226537),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'w_n_ast_errors',\n",
       "  np.float64(0.027019233656974895),\n",
       "  np.float64(0.01139774940279815),\n",
       "  np.float64(0.03120036263957241),\n",
       "  np.float64(0.003478044224510393)],\n",
       " ['i_vocab_size',\n",
       "  'w_n_whitespaces',\n",
       "  np.float64(0.35704324895586087),\n",
       "  np.float64(5.842872470064653e-262),\n",
       "  np.float64(0.4799749441437264),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'w_complexity',\n",
       "  np.float64(0.3698856612386199),\n",
       "  np.float64(1.8733299414234357e-282),\n",
       "  np.float64(0.3471667045967565),\n",
       "  np.float64(7.832752125756156e-247)],\n",
       " ['i_vocab_size',\n",
       "  'w_ast_levels',\n",
       "  np.float64(0.3302646504115752),\n",
       "  np.float64(3.471009545346545e-222),\n",
       "  np.float64(0.3602639731468211),\n",
       "  np.float64(5.192471947474459e-267)],\n",
       " ['i_vocab_size',\n",
       "  'w_vocab_size',\n",
       "  np.float64(0.5523042907844735),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5445199998267021),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'w_nloc',\n",
       "  np.float64(0.39460527303660003),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4353205574189013),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'w_n_ast_nodes',\n",
       "  np.float64(0.4780327375826023),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.4998976758143783),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'w_n_identifiers',\n",
       "  np.float64(0.45402368917089),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.45566772760322843),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'w_n_words',\n",
       "  np.float64(0.5379296732524539),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.5419105841919781),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'e_n_whitespaces',\n",
       "  np.float64(0.28858585499600226),\n",
       "  np.float64(8.522306802507747e-168),\n",
       "  np.float64(0.2718798949110201),\n",
       "  np.float64(2.0042323154485205e-148)],\n",
       " ['i_vocab_size',\n",
       "  'e_n_words',\n",
       "  np.float64(0.204187365146615),\n",
       "  np.float64(3.5160446506487054e-83),\n",
       "  np.float64(0.17111408661457464),\n",
       "  np.float64(1.3242818590259981e-58)],\n",
       " ['i_vocab_size',\n",
       "  'e_vocab_size',\n",
       "  np.float64(0.21736143405351974),\n",
       "  np.float64(2.848348287956501e-94),\n",
       "  np.float64(0.1937083760645016),\n",
       "  np.float64(6.821262484236134e-75)],\n",
       " ['i_vocab_size',\n",
       "  'i_n_whitespaces',\n",
       "  np.float64(0.6730239502066849),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.8832931717617203),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'i_n_words',\n",
       "  np.float64(0.9688011573915183),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.9916811718851848),\n",
       "  np.float64(0.0)],\n",
       " ['i_vocab_size',\n",
       "  'i_vocab_size',\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0)]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(total)\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
